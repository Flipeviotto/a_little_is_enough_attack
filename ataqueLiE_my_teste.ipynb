{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Flipeviotto/a_little_is_enough_attack/blob/Version_1/ataqueLiE_my_teste.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRzGeDdqtWN3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn as nn   # oferece um modulo de rede neural pré definido\n",
        "\n",
        "import torch.optim as optim     # ajusta pesos e biases interativamente para minimizar um loss function\n",
        "                                # exemplo de loss function: SGD, Adam, RMSprop\n",
        "\n",
        "import torch.nn.functional as F # funções comuns para neur. netw. funções de ativação, pooling e loss functions.\n",
        "\n",
        "from torch.utils.data import Subset     # pode criar subconjunto de dataset para validar e treinos especificos.\n",
        "\n",
        "from torchvision.datasets import MNIST  # acessa o dataset MNIST\n",
        "\n",
        "from torch.utils.data import DataLoader # carrega dados do dataset in batches, permite treinar e avaliar a rede neural\n",
        "\n",
        "from torchvision.transforms import ToTensor # converte imagens para tensors\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support # calcula as metricas da evolução\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKqN8Wbftcj3"
      },
      "outputs": [],
      "source": [
        "class Arguments():  # encapsula hiperparametros e opções de configuração for a deep learning model\n",
        "    def __init__(self):     # é um construtor dos atributos abaixo\n",
        "        self.train_batch_size = 64\n",
        "        self.test_batch_size = 64\n",
        "        self.epochs = 20            # quantidade de epocas de treinamento\n",
        "        self.learning_rate = 0.01\n",
        "        self.no_cuda = False\n",
        "        self.n_workers = 10\n",
        "\n",
        "args = Arguments()\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZkGNHh3tdn2"
      },
      "outputs": [],
      "source": [
        "def get_mnist():\n",
        "    return MNIST(root=\"./data\", train=True, download=True, transform=ToTensor()), MNIST(root=\"./data\", train=False, download=True, transform=ToTensor())\n",
        "\n",
        "def prepare_dataset():\n",
        "    trainset, testset = get_mnist()\n",
        "\n",
        "    #Faz a divisão do dataset em partes para cada worker ter o seu próprio conjunto de dados\n",
        "    trainsets = []\n",
        "    parte_size = len(trainset) // args.n_workers z\n",
        "\n",
        "    for i in range(args.n_workers):     # separa cada quantidade de dado em um conjunto de treinamento\n",
        "        parte = Subset(trainset, range(i * parte_size, (i + 1) * parte_size))\n",
        "        trainsets.append(parte)         # cada parte dessa lista será usada para treinar um worker\n",
        "\n",
        "    if len(trainset) % args.n_workers != 0:     # se houver sobra de dados será adicionada na ultima parte\n",
        "        parte_final = Subset(trainset, range(10 * parte_size, len(trainset)))\n",
        "        trainsets.append(parte_final)\n",
        "\n",
        "    #Cria um dataloader para cada worker\n",
        "    trainloaders = []\n",
        "\n",
        "    for trainset_ in trainsets:\n",
        "\n",
        "        trainloaders.append(\n",
        "            DataLoader(trainset_, batch_size=args.train_batch_size, shuffle=False)\n",
        "        )\n",
        "\n",
        "    testloaders = DataLoader(testset, batch_size=args.test_batch_size, shuffle=False)\n",
        "\n",
        "    return trainloaders, testloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rco2PjmTtjya"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):                           # nn.Module define modulos de rede neural\n",
        "    def __init__(self):                         # constroe a classe net\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)        # camada conv 2D, 1 canal de entrada e 20 de saida. kernel de 5\n",
        "                                                            # essa camada serve para extrair caracteristicas das imagens de entrada\n",
        "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)       # camada conv 2D, 20 canais de entrada e 50 de saida, kernel 5.\n",
        "        self.fc1 = nn.Linear(50 * 4 * 4, 512)               # 50*4*4=800 é o tamanho da entrada da camada atual e da saida da camanda anterior.\n",
        "            #fc é uma camada densa                          # tem 512 neuronio de saida\n",
        "        self.fc2 = nn.Linear(512, 10)                       # tem 512 entradas e 10 saidas (é a quantidade de classes possiveis)\n",
        "\n",
        "    def forward(self, x):                           # isso define a sequencia que os dados de entradas (x) serão submetidos para produzir a saida\n",
        "        x = F.relu(self.conv1(x))                   # aplica uma camada de ativação em x e usa uma função de ativação para o resultado\n",
        "        x = F.max_pool2d(x, 2)                      # aplica um kernel de tamanho 2 na entrada, o que reduz a dimenção espacial\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 50 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))                     # é uma camada densa (fc)\n",
        "        x = F.log_softmax(self.fc2(x), dim=1)       # log_softmax serve para normalizar a saida em probabilidades\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90hMAeaxtmlx"
      },
      "outputs": [],
      "source": [
        "def train(args:Arguments, model:list, device, train_loader, optimizer, loss_fn, i):\n",
        "    #treina o modelo local de cada worker apenas com o dataset remetente aquele worker\n",
        "    loss = [0] * args.n_workers                     # inicializa as funções de perdas para cada worker\n",
        "\n",
        "    # loop para cada worker\n",
        "    for j in range(0, args.n_workers):\n",
        "        model[j].train()                       # ajusta o modelo para modo de treinamento\n",
        "        for _, (data, target) in enumerate(train_loader[j]):\n",
        "            data, target = data.to(device), target.to(device)       # move os dados do target para o dispositivo escolhido (cpu ou gpu)\n",
        "            optimizer[j].zero_grad()                                # limpa o gradiente do optimizer do worker para evitar que gradientes desatualizados afetem a atualização do parameto\n",
        "            output = model[j](data)                                 # obtem a predição do worker atual\n",
        "            loss[j] = loss_fn[j](output, target)                    # calcula a perda\n",
        "            loss[j].backward()                                      # calcula o gradiente da perda\n",
        "            optimizer[j].step()                                     # atualiza os parametros do modelo usado o optimizer\n",
        "\n",
        "        print(f'Epoch {i} | Worker: {j} | TRAIN: Last Loss: {loss[j]:.5f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvEemtsRtp_-"
      },
      "outputs": [],
      "source": [
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _, (data, target) in enumerate(test_loader):            # intera sobre cada dado e seu rotulo, _ descarta os index que não serão usados na função\n",
        "            data, target = data.to(device), target.to(device)       # transfere os dados e os rotulos para o dispositivo escolhido\n",
        "            outputs = model(data)                                   # gera as predictions\n",
        "            loss = F.nll_loss(outputs, target).item()               # calcula o erro\n",
        "            pred = outputs.argmax(1, keepdim=True)                  #\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()   # calcula o numero predições corretas\n",
        "\n",
        "            all_predictions.extend(pred.cpu().numpy().flatten())\n",
        "            all_targets.extend(target.cpu().numpy().flatten())\n",
        "\n",
        "        total_samples = len(test_loader.dataset)\n",
        "        precision, recall, f1_score, _ = precision_recall_fscore_support(all_targets, all_predictions, average='weighted', zero_division=1)\n",
        "        accuracy = (correct / total_samples) * 100\n",
        "\n",
        "        with open(f\"teste{wm}.txt\", 'a') as file:\n",
        "            file.write(f'Last Loss: {loss:.4f} | Accuracy: {accuracy:.2f}% | Correct: {correct}/{total_samples} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1-score: {f1_score:.4f}\\n')\n",
        "        print(f'Last Loss: {loss:.4f} | Accuracy: {accuracy:.2f}% | Correct: {correct}/{total_samples} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1-score: {f1_score:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxydGWq4tukH"
      },
      "outputs": [],
      "source": [
        "def fedavg_aggregation(model:list, global_model):\n",
        "    all_params = [list(model_agg.parameters()) for model_agg in model]              # intera pelos modelos de aprendizado federado treinados e retira os pesos e bias (parametros)\n",
        "    average_params = [torch.stack(params).mean(0) for params in zip(*all_params)]   # empilha os parametros e calcula a media e amazena cada média em uma lista\n",
        "\n",
        "    for own_params, avg_params in zip(global_model.parameters(), average_params):   # atualiza o modelo global,\n",
        "        own_params.data.copy_(avg_params)\n",
        "\n",
        "    for i in range(0, len(model)):                                                  #\n",
        "        model[i].load_state_dict(global_model.state_dict())                         #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFfrmyDltxZo"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import norm\n",
        "\n",
        "def ataque(args:Arguments, global_model:Net, model:list, workers_maliciosos:list):\n",
        "    #nova tentativa\n",
        "    total_clientes = args.n_workers\n",
        "    #calcular a taxa de perturbação\n",
        "    s = total_clientes/2 + 1 - len(workers_maliciosos)\n",
        "    possibilidade = (total_clientes-s)/total_clientes\n",
        "    z = norm.cdf(possibilidade)\n",
        "\n",
        "    # somar parametros\n",
        "    soma_parametros = Net().to(device)\n",
        "    media = Net().to(device)\n",
        "    desvio_padrao = Net().to(device)\n",
        "    desvio_padrao_aux = Net().to(device)\n",
        "\n",
        "    for parametro, parametro_media, desvio, desvio_pad in zip(soma_parametros.parameters(), media.parameters(), desvio_padrao_aux.parameters(), desvio_padrao.parameters()):\n",
        "        parametro.data.zero_()\n",
        "        parametro_media.data.zero_()\n",
        "        desvio.data.zero_()\n",
        "        desvio_pad.data.zero_()\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for malicioso in workers_maliciosos:\n",
        "        for parametro1, parametro2 in zip(model[malicioso].parameters(), soma_parametros.parameters()):\n",
        "          parametro2.data += parametro1.data\n",
        "\n",
        "      #calcular media\n",
        "      for parametro2, parametro_media in zip(soma_parametros.parameters(), media.parameters()):\n",
        "        parametro_media.data = parametro2.data/len(workers_maliciosos)\n",
        "\n",
        "      # calculo desvio padrao\n",
        "      for malicioso in workers_maliciosos:\n",
        "        for parametro1, parametro2, parametro_media in zip(model[malicioso].parameters(), desvio_padrao_aux.parameters(), media.parameters()):\n",
        "            diff_squared = (parametro1.data - parametro_media.data) ** 2\n",
        "            parametro2.data += diff_squared  # Acumula diferença ao quadrado\n",
        "\n",
        "      for parametro2, desvio in zip(desvio_padrao_aux.parameters(), desvio_padrao.parameters()):\n",
        "        desvio.data = torch.sqrt(parametro2.data / len(workers_maliciosos))\n",
        "\n",
        "      # alterar parametros\n",
        "      for malicioso in workers_maliciosos:\n",
        "        #print(\"inicio da iteracao\")\n",
        "        for parametro, desvio, parametro_media in zip(model[malicioso].parameters(), desvio_padrao.parameters(), media.parameters()):\n",
        "          #print(\"parametro\")\n",
        "          #print(parametro.data)\n",
        "          #print(\"desvio\")\n",
        "          #print(desvio.data)\n",
        "          parametro.data = parametro_media.data + z * desvio.data\n",
        "          #print(\"parametro\")\n",
        "          #print(parametro.data)\n",
        "\n",
        "\n",
        "\n",
        "    return 0\n",
        "\n",
        "\n",
        "    print(\"inicio ataque:\")\n",
        "\n",
        "\n",
        "    model_dict = [model[i].state_dict() for i in workers_maliciosos]\n",
        "    model_flattened = [torch.cat([param.view(-1) for param in model_dict[i].values()]) for i in workers_maliciosos]\n",
        "\n",
        "    #calcular a taxa de perturbação\n",
        "    s = total_clientes/2 + 1 - len(workers_maliciosos)\n",
        "    possibilidade = (total_clientes-s)/total_clientes\n",
        "    z = norm.ppf(possibilidade)\n",
        "\n",
        "    media_pesos = []\n",
        "    media_dimensao=[]\n",
        "\n",
        "    for i, _ in enumerate(model[0].children()):\n",
        "      media_pesos.append(0)\n",
        "\n",
        "\n",
        "\n",
        "    for w in [0]:\n",
        "      for i, layer in enumerate(model[w].children()):\n",
        "          if hasattr(layer, 'weight'):\n",
        "            pesos=layer.weight.data\n",
        "            print(\"pesos\")\n",
        "            print(pesos)\n",
        "\n",
        "\n",
        "\n",
        "    print(\"media_dimensao\")\n",
        "    print(media_dimensao)\n",
        "\n",
        "    print(\"\\nmodel_dict\\n\")\n",
        "    print(model_dict)\n",
        "    print(\"\\nmodel dict[0]\\n\")\n",
        "    print(model_dict[0])\n",
        "\n",
        "    print(\"\\nflatend:\")\n",
        "    print(model_flattened)\n",
        "    print(\"\\noutro 1\\n\\n\")\n",
        "    print(model_flattened[0].shape)\n",
        "    print(\"\\noutro 2\\n\\n\")\n",
        "    print(model_flattened[0])\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for w in workers_maliciosos:\n",
        "        for i, layer in enumerate(model[w].children()):\n",
        "          if hasattr(layer, 'weight'):\n",
        "            #layer.weight.data = media_pesos[i] + z * desvio_padrao[i]\n",
        "            print(\" \")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return 0\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZnIu9qTt6X8",
        "outputId": "683e04fb-9fe3-4dbb-891f-8f7b5e159f0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de workers maliciosos: 1\n",
            "Epoch 1 | Worker: 0 | TRAIN: Last Loss: 2.26885\n",
            "Epoch 1 | Worker: 1 | TRAIN: Last Loss: 2.25666\n",
            "Epoch 1 | Worker: 2 | TRAIN: Last Loss: 2.24423\n",
            "Epoch 1 | Worker: 3 | TRAIN: Last Loss: 2.27278\n",
            "Epoch 1 | Worker: 4 | TRAIN: Last Loss: 2.26814\n",
            "Epoch 1 | Worker: 5 | TRAIN: Last Loss: 2.26743\n",
            "Epoch 1 | Worker: 6 | TRAIN: Last Loss: 2.27936\n",
            "Epoch 1 | Worker: 7 | TRAIN: Last Loss: 2.26334\n",
            "Epoch 1 | Worker: 8 | TRAIN: Last Loss: 2.25437\n",
            "Epoch 1 | Worker: 9 | TRAIN: Last Loss: 2.28967\n",
            "Epoch 2 | Worker: 0 | TRAIN: Last Loss: 2.18270\n",
            "Epoch 2 | Worker: 1 | TRAIN: Last Loss: 2.10908\n",
            "Epoch 2 | Worker: 2 | TRAIN: Last Loss: 2.08641\n",
            "Epoch 2 | Worker: 3 | TRAIN: Last Loss: 2.21701\n",
            "Epoch 2 | Worker: 4 | TRAIN: Last Loss: 2.18877\n",
            "Epoch 2 | Worker: 5 | TRAIN: Last Loss: 2.18278\n",
            "Epoch 2 | Worker: 6 | TRAIN: Last Loss: 2.23254\n",
            "Epoch 2 | Worker: 7 | TRAIN: Last Loss: 2.17366\n",
            "Epoch 2 | Worker: 8 | TRAIN: Last Loss: 2.15470\n",
            "Epoch 2 | Worker: 9 | TRAIN: Last Loss: 2.27132\n",
            "Epoch 3 | Worker: 0 | TRAIN: Last Loss: 1.81013\n",
            "Epoch 3 | Worker: 1 | TRAIN: Last Loss: 1.48665\n",
            "Epoch 3 | Worker: 2 | TRAIN: Last Loss: 1.29992\n",
            "Epoch 3 | Worker: 3 | TRAIN: Last Loss: 2.00924\n",
            "Epoch 3 | Worker: 4 | TRAIN: Last Loss: 1.82491\n",
            "Epoch 3 | Worker: 5 | TRAIN: Last Loss: 1.84573\n",
            "Epoch 3 | Worker: 6 | TRAIN: Last Loss: 2.06013\n",
            "Epoch 3 | Worker: 7 | TRAIN: Last Loss: 1.73282\n",
            "Epoch 3 | Worker: 8 | TRAIN: Last Loss: 1.70831\n",
            "Epoch 3 | Worker: 9 | TRAIN: Last Loss: 2.22834\n",
            "Epoch 4 | Worker: 0 | TRAIN: Last Loss: 0.81845\n",
            "Epoch 4 | Worker: 1 | TRAIN: Last Loss: 0.82292\n",
            "Epoch 4 | Worker: 2 | TRAIN: Last Loss: 0.50813\n",
            "Epoch 4 | Worker: 3 | TRAIN: Last Loss: 1.23380\n",
            "Epoch 4 | Worker: 4 | TRAIN: Last Loss: 1.14230\n",
            "Epoch 4 | Worker: 5 | TRAIN: Last Loss: 0.98563\n",
            "Epoch 4 | Worker: 6 | TRAIN: Last Loss: 1.22027\n",
            "Epoch 4 | Worker: 7 | TRAIN: Last Loss: 0.84818\n",
            "Epoch 4 | Worker: 8 | TRAIN: Last Loss: 0.87082\n",
            "Epoch 4 | Worker: 9 | TRAIN: Last Loss: 2.06531\n",
            "Last Loss: 2.2849 | Accuracy: 32.72% | Correct: 3272/10000 | Precision: 0.7132 | Recall: 0.3272 | F1-score: 0.2242\n",
            "Epoch 5 | Worker: 0 | TRAIN: Last Loss: 2.25320\n",
            "Epoch 5 | Worker: 1 | TRAIN: Last Loss: 2.26412\n",
            "Epoch 5 | Worker: 2 | TRAIN: Last Loss: 2.25842\n",
            "Epoch 5 | Worker: 3 | TRAIN: Last Loss: 2.25984\n",
            "Epoch 5 | Worker: 4 | TRAIN: Last Loss: 2.27117\n",
            "Epoch 5 | Worker: 5 | TRAIN: Last Loss: 2.26548\n",
            "Epoch 5 | Worker: 6 | TRAIN: Last Loss: 2.25970\n",
            "Epoch 5 | Worker: 7 | TRAIN: Last Loss: 2.26148\n",
            "Epoch 5 | Worker: 8 | TRAIN: Last Loss: 2.26617\n",
            "Epoch 5 | Worker: 9 | TRAIN: Last Loss: 2.26218\n",
            "Epoch 6 | Worker: 0 | TRAIN: Last Loss: 2.17709\n",
            "Epoch 6 | Worker: 1 | TRAIN: Last Loss: 2.19872\n",
            "Epoch 6 | Worker: 2 | TRAIN: Last Loss: 2.19589\n",
            "Epoch 6 | Worker: 3 | TRAIN: Last Loss: 2.18686\n",
            "Epoch 6 | Worker: 4 | TRAIN: Last Loss: 2.22012\n",
            "Epoch 6 | Worker: 5 | TRAIN: Last Loss: 2.20911\n",
            "Epoch 6 | Worker: 6 | TRAIN: Last Loss: 2.19269\n",
            "Epoch 6 | Worker: 7 | TRAIN: Last Loss: 2.19599\n",
            "Epoch 6 | Worker: 8 | TRAIN: Last Loss: 2.21304\n",
            "Epoch 6 | Worker: 9 | TRAIN: Last Loss: 2.20328\n",
            "Epoch 7 | Worker: 0 | TRAIN: Last Loss: 1.83786\n",
            "Epoch 7 | Worker: 1 | TRAIN: Last Loss: 1.91724\n",
            "Epoch 7 | Worker: 2 | TRAIN: Last Loss: 1.94570\n",
            "Epoch 7 | Worker: 3 | TRAIN: Last Loss: 1.85992\n",
            "Epoch 7 | Worker: 4 | TRAIN: Last Loss: 1.96116\n",
            "Epoch 7 | Worker: 5 | TRAIN: Last Loss: 2.00201\n",
            "Epoch 7 | Worker: 6 | TRAIN: Last Loss: 1.89620\n",
            "Epoch 7 | Worker: 7 | TRAIN: Last Loss: 1.90746\n",
            "Epoch 7 | Worker: 8 | TRAIN: Last Loss: 2.01540\n",
            "Epoch 7 | Worker: 9 | TRAIN: Last Loss: 1.93961\n",
            "Epoch 8 | Worker: 0 | TRAIN: Last Loss: 1.05108\n",
            "Epoch 8 | Worker: 1 | TRAIN: Last Loss: 1.24047\n",
            "Epoch 8 | Worker: 2 | TRAIN: Last Loss: 1.16220\n",
            "Epoch 8 | Worker: 3 | TRAIN: Last Loss: 1.18060\n",
            "Epoch 8 | Worker: 4 | TRAIN: Last Loss: 1.35516\n",
            "Epoch 8 | Worker: 5 | TRAIN: Last Loss: 1.34934\n",
            "Epoch 8 | Worker: 6 | TRAIN: Last Loss: 1.08713\n",
            "Epoch 8 | Worker: 7 | TRAIN: Last Loss: 1.13305\n",
            "Epoch 8 | Worker: 8 | TRAIN: Last Loss: 1.36266\n",
            "Epoch 8 | Worker: 9 | TRAIN: Last Loss: 1.13233\n",
            "Last Loss: 1.0488 | Accuracy: 71.73% | Correct: 7173/10000 | Precision: 0.7189 | Recall: 0.7173 | F1-score: 0.7005\n",
            "Epoch 9 | Worker: 0 | TRAIN: Last Loss: 0.74445\n",
            "Epoch 9 | Worker: 1 | TRAIN: Last Loss: 0.89348\n",
            "Epoch 9 | Worker: 2 | TRAIN: Last Loss: 0.57521\n",
            "Epoch 9 | Worker: 3 | TRAIN: Last Loss: 1.05108\n",
            "Epoch 9 | Worker: 4 | TRAIN: Last Loss: 1.12296\n",
            "Epoch 9 | Worker: 5 | TRAIN: Last Loss: 0.86217\n",
            "Epoch 9 | Worker: 6 | TRAIN: Last Loss: 0.76144\n",
            "Epoch 9 | Worker: 7 | TRAIN: Last Loss: 0.74149\n",
            "Epoch 9 | Worker: 8 | TRAIN: Last Loss: 0.99637\n",
            "Epoch 9 | Worker: 9 | TRAIN: Last Loss: 0.73455\n",
            "Epoch 10 | Worker: 0 | TRAIN: Last Loss: 0.60925\n",
            "Epoch 10 | Worker: 1 | TRAIN: Last Loss: 0.71290\n",
            "Epoch 10 | Worker: 2 | TRAIN: Last Loss: 0.39494\n",
            "Epoch 10 | Worker: 3 | TRAIN: Last Loss: 1.04819\n",
            "Epoch 10 | Worker: 4 | TRAIN: Last Loss: 1.03663\n",
            "Epoch 10 | Worker: 5 | TRAIN: Last Loss: 0.68783\n",
            "Epoch 10 | Worker: 6 | TRAIN: Last Loss: 0.71251\n",
            "Epoch 10 | Worker: 7 | TRAIN: Last Loss: 0.64844\n",
            "Epoch 10 | Worker: 8 | TRAIN: Last Loss: 0.88721\n",
            "Epoch 10 | Worker: 9 | TRAIN: Last Loss: 0.56875\n",
            "Epoch 11 | Worker: 0 | TRAIN: Last Loss: 0.53204\n",
            "Epoch 11 | Worker: 1 | TRAIN: Last Loss: 0.62122\n",
            "Epoch 11 | Worker: 2 | TRAIN: Last Loss: 0.31728\n",
            "Epoch 11 | Worker: 3 | TRAIN: Last Loss: 1.04738\n",
            "Epoch 11 | Worker: 4 | TRAIN: Last Loss: 0.97628\n",
            "Epoch 11 | Worker: 5 | TRAIN: Last Loss: 0.57944\n",
            "Epoch 11 | Worker: 6 | TRAIN: Last Loss: 0.67683\n",
            "Epoch 11 | Worker: 7 | TRAIN: Last Loss: 0.59544\n",
            "Epoch 11 | Worker: 8 | TRAIN: Last Loss: 0.82449\n",
            "Epoch 11 | Worker: 9 | TRAIN: Last Loss: 0.48643\n",
            "Epoch 12 | Worker: 0 | TRAIN: Last Loss: 0.48230\n",
            "Epoch 12 | Worker: 1 | TRAIN: Last Loss: 0.56393\n",
            "Epoch 12 | Worker: 2 | TRAIN: Last Loss: 0.27632\n",
            "Epoch 12 | Worker: 3 | TRAIN: Last Loss: 1.02713\n",
            "Epoch 12 | Worker: 4 | TRAIN: Last Loss: 0.92418\n",
            "Epoch 12 | Worker: 5 | TRAIN: Last Loss: 0.50251\n",
            "Epoch 12 | Worker: 6 | TRAIN: Last Loss: 0.63906\n",
            "Epoch 12 | Worker: 7 | TRAIN: Last Loss: 0.54801\n",
            "Epoch 12 | Worker: 8 | TRAIN: Last Loss: 0.77977\n",
            "Epoch 12 | Worker: 9 | TRAIN: Last Loss: 0.43060\n",
            "Last Loss: 0.4155 | Accuracy: 83.57% | Correct: 8357/10000 | Precision: 0.8375 | Recall: 0.8357 | F1-score: 0.8349\n",
            "Epoch 13 | Worker: 0 | TRAIN: Last Loss: 0.44326\n",
            "Epoch 13 | Worker: 1 | TRAIN: Last Loss: 0.50972\n",
            "Epoch 13 | Worker: 2 | TRAIN: Last Loss: 0.25444\n",
            "Epoch 13 | Worker: 3 | TRAIN: Last Loss: 1.02605\n",
            "Epoch 13 | Worker: 4 | TRAIN: Last Loss: 0.88060\n",
            "Epoch 13 | Worker: 5 | TRAIN: Last Loss: 0.46309\n",
            "Epoch 13 | Worker: 6 | TRAIN: Last Loss: 0.60754\n",
            "Epoch 13 | Worker: 7 | TRAIN: Last Loss: 0.52236\n",
            "Epoch 13 | Worker: 8 | TRAIN: Last Loss: 0.73100\n",
            "Epoch 13 | Worker: 9 | TRAIN: Last Loss: 0.40041\n",
            "Epoch 14 | Worker: 0 | TRAIN: Last Loss: 0.40436\n",
            "Epoch 14 | Worker: 1 | TRAIN: Last Loss: 0.46402\n",
            "Epoch 14 | Worker: 2 | TRAIN: Last Loss: 0.23165\n",
            "Epoch 14 | Worker: 3 | TRAIN: Last Loss: 0.96084\n",
            "Epoch 14 | Worker: 4 | TRAIN: Last Loss: 0.83251\n",
            "Epoch 14 | Worker: 5 | TRAIN: Last Loss: 0.41063\n",
            "Epoch 14 | Worker: 6 | TRAIN: Last Loss: 0.56194\n",
            "Epoch 14 | Worker: 7 | TRAIN: Last Loss: 0.48555\n",
            "Epoch 14 | Worker: 8 | TRAIN: Last Loss: 0.69890\n",
            "Epoch 14 | Worker: 9 | TRAIN: Last Loss: 0.36105\n",
            "Epoch 15 | Worker: 0 | TRAIN: Last Loss: 0.36873\n",
            "Epoch 15 | Worker: 1 | TRAIN: Last Loss: 0.42181\n",
            "Epoch 15 | Worker: 2 | TRAIN: Last Loss: 0.21519\n",
            "Epoch 15 | Worker: 3 | TRAIN: Last Loss: 0.90265\n",
            "Epoch 15 | Worker: 4 | TRAIN: Last Loss: 0.78953\n",
            "Epoch 15 | Worker: 5 | TRAIN: Last Loss: 0.36866\n",
            "Epoch 15 | Worker: 6 | TRAIN: Last Loss: 0.52225\n",
            "Epoch 15 | Worker: 7 | TRAIN: Last Loss: 0.45597\n",
            "Epoch 15 | Worker: 8 | TRAIN: Last Loss: 0.67091\n",
            "Epoch 15 | Worker: 9 | TRAIN: Last Loss: 0.32450\n",
            "Epoch 16 | Worker: 0 | TRAIN: Last Loss: 0.33671\n",
            "Epoch 16 | Worker: 1 | TRAIN: Last Loss: 0.38572\n",
            "Epoch 16 | Worker: 2 | TRAIN: Last Loss: 0.20265\n",
            "Epoch 16 | Worker: 3 | TRAIN: Last Loss: 0.84773\n",
            "Epoch 16 | Worker: 4 | TRAIN: Last Loss: 0.74657\n",
            "Epoch 16 | Worker: 5 | TRAIN: Last Loss: 0.33353\n",
            "Epoch 16 | Worker: 6 | TRAIN: Last Loss: 0.48541\n",
            "Epoch 16 | Worker: 7 | TRAIN: Last Loss: 0.42889\n",
            "Epoch 16 | Worker: 8 | TRAIN: Last Loss: 0.64257\n",
            "Epoch 16 | Worker: 9 | TRAIN: Last Loss: 0.29512\n",
            "Last Loss: 0.2599 | Accuracy: 87.75% | Correct: 8775/10000 | Precision: 0.8786 | Recall: 0.8775 | F1-score: 0.8772\n",
            "Epoch 17 | Worker: 0 | TRAIN: Last Loss: 0.30723\n",
            "Epoch 17 | Worker: 1 | TRAIN: Last Loss: 0.34295\n",
            "Epoch 17 | Worker: 2 | TRAIN: Last Loss: 0.20080\n",
            "Epoch 17 | Worker: 3 | TRAIN: Last Loss: 0.83206\n",
            "Epoch 17 | Worker: 4 | TRAIN: Last Loss: 0.72131\n",
            "Epoch 17 | Worker: 5 | TRAIN: Last Loss: 0.32610\n",
            "Epoch 17 | Worker: 6 | TRAIN: Last Loss: 0.47816\n",
            "Epoch 17 | Worker: 7 | TRAIN: Last Loss: 0.42088\n",
            "Epoch 17 | Worker: 8 | TRAIN: Last Loss: 0.61069\n",
            "Epoch 17 | Worker: 9 | TRAIN: Last Loss: 0.27964\n",
            "Epoch 18 | Worker: 0 | TRAIN: Last Loss: 0.27844\n",
            "Epoch 18 | Worker: 1 | TRAIN: Last Loss: 0.31579\n",
            "Epoch 18 | Worker: 2 | TRAIN: Last Loss: 0.19345\n",
            "Epoch 18 | Worker: 3 | TRAIN: Last Loss: 0.76017\n",
            "Epoch 18 | Worker: 4 | TRAIN: Last Loss: 0.67736\n",
            "Epoch 18 | Worker: 5 | TRAIN: Last Loss: 0.29562\n",
            "Epoch 18 | Worker: 6 | TRAIN: Last Loss: 0.44358\n",
            "Epoch 18 | Worker: 7 | TRAIN: Last Loss: 0.39540\n",
            "Epoch 18 | Worker: 8 | TRAIN: Last Loss: 0.58407\n",
            "Epoch 18 | Worker: 9 | TRAIN: Last Loss: 0.25355\n",
            "Epoch 19 | Worker: 0 | TRAIN: Last Loss: 0.25592\n",
            "Epoch 19 | Worker: 1 | TRAIN: Last Loss: 0.29367\n",
            "Epoch 19 | Worker: 2 | TRAIN: Last Loss: 0.18785\n",
            "Epoch 19 | Worker: 3 | TRAIN: Last Loss: 0.70118\n",
            "Epoch 19 | Worker: 4 | TRAIN: Last Loss: 0.63576\n",
            "Epoch 19 | Worker: 5 | TRAIN: Last Loss: 0.27109\n",
            "Epoch 19 | Worker: 6 | TRAIN: Last Loss: 0.41512\n",
            "Epoch 19 | Worker: 7 | TRAIN: Last Loss: 0.37609\n",
            "Epoch 19 | Worker: 8 | TRAIN: Last Loss: 0.56336\n",
            "Epoch 19 | Worker: 9 | TRAIN: Last Loss: 0.23129\n",
            "Epoch 20 | Worker: 0 | TRAIN: Last Loss: 0.23499\n",
            "Epoch 20 | Worker: 1 | TRAIN: Last Loss: 0.27351\n",
            "Epoch 20 | Worker: 2 | TRAIN: Last Loss: 0.18158\n",
            "Epoch 20 | Worker: 3 | TRAIN: Last Loss: 0.65293\n",
            "Epoch 20 | Worker: 4 | TRAIN: Last Loss: 0.59755\n",
            "Epoch 20 | Worker: 5 | TRAIN: Last Loss: 0.24941\n",
            "Epoch 20 | Worker: 6 | TRAIN: Last Loss: 0.39208\n",
            "Epoch 20 | Worker: 7 | TRAIN: Last Loss: 0.35427\n",
            "Epoch 20 | Worker: 8 | TRAIN: Last Loss: 0.54336\n",
            "Epoch 20 | Worker: 9 | TRAIN: Last Loss: 0.21070\n",
            "Last Loss: 0.1664 | Accuracy: 90.28% | Correct: 9028/10000 | Precision: 0.9036 | Recall: 0.9028 | F1-score: 0.9027\n",
            "Quantidade de workers maliciosos: 2\n",
            "Epoch 1 | Worker: 0 | TRAIN: Last Loss: 2.24269\n",
            "Epoch 1 | Worker: 1 | TRAIN: Last Loss: 2.27875\n",
            "Epoch 1 | Worker: 2 | TRAIN: Last Loss: 2.27486\n",
            "Epoch 1 | Worker: 3 | TRAIN: Last Loss: 2.27644\n",
            "Epoch 1 | Worker: 4 | TRAIN: Last Loss: 2.27964\n",
            "Epoch 1 | Worker: 5 | TRAIN: Last Loss: 2.26609\n",
            "Epoch 1 | Worker: 6 | TRAIN: Last Loss: 2.24844\n",
            "Epoch 1 | Worker: 7 | TRAIN: Last Loss: 2.25376\n",
            "Epoch 1 | Worker: 8 | TRAIN: Last Loss: 2.27794\n",
            "Epoch 1 | Worker: 9 | TRAIN: Last Loss: 2.26409\n",
            "Epoch 2 | Worker: 0 | TRAIN: Last Loss: 2.28190\n",
            "Epoch 2 | Worker: 1 | TRAIN: Last Loss: 2.29169\n",
            "Epoch 2 | Worker: 2 | TRAIN: Last Loss: 2.20523\n",
            "Epoch 2 | Worker: 3 | TRAIN: Last Loss: 2.21744\n",
            "Epoch 2 | Worker: 4 | TRAIN: Last Loss: 2.23666\n",
            "Epoch 2 | Worker: 5 | TRAIN: Last Loss: 2.17869\n",
            "Epoch 2 | Worker: 6 | TRAIN: Last Loss: 2.07678\n",
            "Epoch 2 | Worker: 7 | TRAIN: Last Loss: 2.09233\n",
            "Epoch 2 | Worker: 8 | TRAIN: Last Loss: 2.23189\n",
            "Epoch 2 | Worker: 9 | TRAIN: Last Loss: 2.17125\n",
            "Epoch 3 | Worker: 0 | TRAIN: Last Loss: 2.29301\n",
            "Epoch 3 | Worker: 1 | TRAIN: Last Loss: 2.29533\n",
            "Epoch 3 | Worker: 2 | TRAIN: Last Loss: 1.95057\n",
            "Epoch 3 | Worker: 3 | TRAIN: Last Loss: 1.99701\n",
            "Epoch 3 | Worker: 4 | TRAIN: Last Loss: 2.07881\n",
            "Epoch 3 | Worker: 5 | TRAIN: Last Loss: 1.78341\n",
            "Epoch 3 | Worker: 6 | TRAIN: Last Loss: 1.24349\n",
            "Epoch 3 | Worker: 7 | TRAIN: Last Loss: 1.34956\n",
            "Epoch 3 | Worker: 8 | TRAIN: Last Loss: 2.07917\n",
            "Epoch 3 | Worker: 9 | TRAIN: Last Loss: 1.70215\n",
            "Epoch 4 | Worker: 0 | TRAIN: Last Loss: 2.29432\n",
            "Epoch 4 | Worker: 1 | TRAIN: Last Loss: 2.29762\n",
            "Epoch 4 | Worker: 2 | TRAIN: Last Loss: 1.05404\n",
            "Epoch 4 | Worker: 3 | TRAIN: Last Loss: 1.14532\n",
            "Epoch 4 | Worker: 4 | TRAIN: Last Loss: 1.38833\n",
            "Epoch 4 | Worker: 5 | TRAIN: Last Loss: 0.83776\n",
            "Epoch 4 | Worker: 6 | TRAIN: Last Loss: 0.60289\n",
            "Epoch 4 | Worker: 7 | TRAIN: Last Loss: 0.65560\n",
            "Epoch 4 | Worker: 8 | TRAIN: Last Loss: 1.35528\n",
            "Epoch 4 | Worker: 9 | TRAIN: Last Loss: 0.72779\n",
            "Last Loss: 2.6061 | Accuracy: 10.10% | Correct: 1010/10000 | Precision: 0.9092 | Recall: 0.1010 | F1-score: 0.0185\n",
            "Epoch 5 | Worker: 0 | TRAIN: Last Loss: 2.28956\n",
            "Epoch 5 | Worker: 1 | TRAIN: Last Loss: 2.29814\n",
            "Epoch 5 | Worker: 2 | TRAIN: Last Loss: 2.29698\n",
            "Epoch 5 | Worker: 3 | TRAIN: Last Loss: 2.29521\n",
            "Epoch 5 | Worker: 4 | TRAIN: Last Loss: 2.29336\n",
            "Epoch 5 | Worker: 5 | TRAIN: Last Loss: 2.30310\n",
            "Epoch 5 | Worker: 6 | TRAIN: Last Loss: 2.29651\n",
            "Epoch 5 | Worker: 7 | TRAIN: Last Loss: 2.29477\n",
            "Epoch 5 | Worker: 8 | TRAIN: Last Loss: 2.30642\n",
            "Epoch 5 | Worker: 9 | TRAIN: Last Loss: 2.29967\n",
            "Epoch 6 | Worker: 0 | TRAIN: Last Loss: 2.28403\n",
            "Epoch 6 | Worker: 1 | TRAIN: Last Loss: 2.29524\n",
            "Epoch 6 | Worker: 2 | TRAIN: Last Loss: 2.29332\n",
            "Epoch 6 | Worker: 3 | TRAIN: Last Loss: 2.29192\n",
            "Epoch 6 | Worker: 4 | TRAIN: Last Loss: 2.28924\n",
            "Epoch 6 | Worker: 5 | TRAIN: Last Loss: 2.30142\n",
            "Epoch 6 | Worker: 6 | TRAIN: Last Loss: 2.29335\n",
            "Epoch 6 | Worker: 7 | TRAIN: Last Loss: 2.29117\n",
            "Epoch 6 | Worker: 8 | TRAIN: Last Loss: 2.30399\n",
            "Epoch 6 | Worker: 9 | TRAIN: Last Loss: 2.29669\n",
            "Epoch 7 | Worker: 0 | TRAIN: Last Loss: 2.27870\n",
            "Epoch 7 | Worker: 1 | TRAIN: Last Loss: 2.29209\n",
            "Epoch 7 | Worker: 2 | TRAIN: Last Loss: 2.28939\n",
            "Epoch 7 | Worker: 3 | TRAIN: Last Loss: 2.28825\n",
            "Epoch 7 | Worker: 4 | TRAIN: Last Loss: 2.28470\n",
            "Epoch 7 | Worker: 5 | TRAIN: Last Loss: 2.29907\n",
            "Epoch 7 | Worker: 6 | TRAIN: Last Loss: 2.28989\n",
            "Epoch 7 | Worker: 7 | TRAIN: Last Loss: 2.28747\n",
            "Epoch 7 | Worker: 8 | TRAIN: Last Loss: 2.30129\n",
            "Epoch 7 | Worker: 9 | TRAIN: Last Loss: 2.29315\n",
            "Epoch 8 | Worker: 0 | TRAIN: Last Loss: 2.27302\n",
            "Epoch 8 | Worker: 1 | TRAIN: Last Loss: 2.28860\n",
            "Epoch 8 | Worker: 2 | TRAIN: Last Loss: 2.28479\n",
            "Epoch 8 | Worker: 3 | TRAIN: Last Loss: 2.28379\n",
            "Epoch 8 | Worker: 4 | TRAIN: Last Loss: 2.27946\n",
            "Epoch 8 | Worker: 5 | TRAIN: Last Loss: 2.29618\n",
            "Epoch 8 | Worker: 6 | TRAIN: Last Loss: 2.28582\n",
            "Epoch 8 | Worker: 7 | TRAIN: Last Loss: 2.28318\n",
            "Epoch 8 | Worker: 8 | TRAIN: Last Loss: 2.29788\n",
            "Epoch 8 | Worker: 9 | TRAIN: Last Loss: 2.28865\n",
            "Last Loss: 2.2839 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Epoch 9 | Worker: 0 | TRAIN: Last Loss: 2.26816\n",
            "Epoch 9 | Worker: 1 | TRAIN: Last Loss: 2.28594\n",
            "Epoch 9 | Worker: 2 | TRAIN: Last Loss: 2.27974\n",
            "Epoch 9 | Worker: 3 | TRAIN: Last Loss: 2.27921\n",
            "Epoch 9 | Worker: 4 | TRAIN: Last Loss: 2.27395\n",
            "Epoch 9 | Worker: 5 | TRAIN: Last Loss: 2.28840\n",
            "Epoch 9 | Worker: 6 | TRAIN: Last Loss: 2.28114\n",
            "Epoch 9 | Worker: 7 | TRAIN: Last Loss: 2.27848\n",
            "Epoch 9 | Worker: 8 | TRAIN: Last Loss: 2.29612\n",
            "Epoch 9 | Worker: 9 | TRAIN: Last Loss: 2.28486\n",
            "Epoch 10 | Worker: 0 | TRAIN: Last Loss: 2.26039\n",
            "Epoch 10 | Worker: 1 | TRAIN: Last Loss: 2.28076\n",
            "Epoch 10 | Worker: 2 | TRAIN: Last Loss: 2.27277\n",
            "Epoch 10 | Worker: 3 | TRAIN: Last Loss: 2.27250\n",
            "Epoch 10 | Worker: 4 | TRAIN: Last Loss: 2.26669\n",
            "Epoch 10 | Worker: 5 | TRAIN: Last Loss: 2.28270\n",
            "Epoch 10 | Worker: 6 | TRAIN: Last Loss: 2.27502\n",
            "Epoch 10 | Worker: 7 | TRAIN: Last Loss: 2.27222\n",
            "Epoch 10 | Worker: 8 | TRAIN: Last Loss: 2.29015\n",
            "Epoch 10 | Worker: 9 | TRAIN: Last Loss: 2.27828\n",
            "Epoch 11 | Worker: 0 | TRAIN: Last Loss: 2.25064\n",
            "Epoch 11 | Worker: 1 | TRAIN: Last Loss: 2.27398\n",
            "Epoch 11 | Worker: 2 | TRAIN: Last Loss: 2.26390\n",
            "Epoch 11 | Worker: 3 | TRAIN: Last Loss: 2.26356\n",
            "Epoch 11 | Worker: 4 | TRAIN: Last Loss: 2.25760\n",
            "Epoch 11 | Worker: 5 | TRAIN: Last Loss: 2.27533\n",
            "Epoch 11 | Worker: 6 | TRAIN: Last Loss: 2.26716\n",
            "Epoch 11 | Worker: 7 | TRAIN: Last Loss: 2.26452\n",
            "Epoch 11 | Worker: 8 | TRAIN: Last Loss: 2.28226\n",
            "Epoch 11 | Worker: 9 | TRAIN: Last Loss: 2.26958\n",
            "Epoch 12 | Worker: 0 | TRAIN: Last Loss: 2.23776\n",
            "Epoch 12 | Worker: 1 | TRAIN: Last Loss: 2.26465\n",
            "Epoch 12 | Worker: 2 | TRAIN: Last Loss: 2.25225\n",
            "Epoch 12 | Worker: 3 | TRAIN: Last Loss: 2.25120\n",
            "Epoch 12 | Worker: 4 | TRAIN: Last Loss: 2.24581\n",
            "Epoch 12 | Worker: 5 | TRAIN: Last Loss: 2.26570\n",
            "Epoch 12 | Worker: 6 | TRAIN: Last Loss: 2.25659\n",
            "Epoch 12 | Worker: 7 | TRAIN: Last Loss: 2.25478\n",
            "Epoch 12 | Worker: 8 | TRAIN: Last Loss: 2.27143\n",
            "Epoch 12 | Worker: 9 | TRAIN: Last Loss: 2.25754\n",
            "Last Loss: 2.2515 | Accuracy: 23.49% | Correct: 2349/10000 | Precision: 0.8018 | Recall: 0.2349 | F1-score: 0.1313\n",
            "Epoch 13 | Worker: 0 | TRAIN: Last Loss: 2.22295\n",
            "Epoch 13 | Worker: 1 | TRAIN: Last Loss: 2.25334\n",
            "Epoch 13 | Worker: 2 | TRAIN: Last Loss: 2.23514\n",
            "Epoch 13 | Worker: 3 | TRAIN: Last Loss: 2.23563\n",
            "Epoch 13 | Worker: 4 | TRAIN: Last Loss: 2.23118\n",
            "Epoch 13 | Worker: 5 | TRAIN: Last Loss: 2.24515\n",
            "Epoch 13 | Worker: 6 | TRAIN: Last Loss: 2.24157\n",
            "Epoch 13 | Worker: 7 | TRAIN: Last Loss: 2.24192\n",
            "Epoch 13 | Worker: 8 | TRAIN: Last Loss: 2.26072\n",
            "Epoch 13 | Worker: 9 | TRAIN: Last Loss: 2.24701\n",
            "Epoch 14 | Worker: 0 | TRAIN: Last Loss: 2.19818\n",
            "Epoch 14 | Worker: 1 | TRAIN: Last Loss: 2.23349\n",
            "Epoch 14 | Worker: 2 | TRAIN: Last Loss: 2.21174\n",
            "Epoch 14 | Worker: 3 | TRAIN: Last Loss: 2.21027\n",
            "Epoch 14 | Worker: 4 | TRAIN: Last Loss: 2.20921\n",
            "Epoch 14 | Worker: 5 | TRAIN: Last Loss: 2.22547\n",
            "Epoch 14 | Worker: 6 | TRAIN: Last Loss: 2.21947\n",
            "Epoch 14 | Worker: 7 | TRAIN: Last Loss: 2.22297\n",
            "Epoch 14 | Worker: 8 | TRAIN: Last Loss: 2.23886\n",
            "Epoch 14 | Worker: 9 | TRAIN: Last Loss: 2.22379\n",
            "Epoch 15 | Worker: 0 | TRAIN: Last Loss: 2.15973\n",
            "Epoch 15 | Worker: 1 | TRAIN: Last Loss: 2.20168\n",
            "Epoch 15 | Worker: 2 | TRAIN: Last Loss: 2.17646\n",
            "Epoch 15 | Worker: 3 | TRAIN: Last Loss: 2.16933\n",
            "Epoch 15 | Worker: 4 | TRAIN: Last Loss: 2.17619\n",
            "Epoch 15 | Worker: 5 | TRAIN: Last Loss: 2.19697\n",
            "Epoch 15 | Worker: 6 | TRAIN: Last Loss: 2.18518\n",
            "Epoch 15 | Worker: 7 | TRAIN: Last Loss: 2.19428\n",
            "Epoch 15 | Worker: 8 | TRAIN: Last Loss: 2.20466\n",
            "Epoch 15 | Worker: 9 | TRAIN: Last Loss: 2.18399\n",
            "Epoch 16 | Worker: 0 | TRAIN: Last Loss: 2.09415\n",
            "Epoch 16 | Worker: 1 | TRAIN: Last Loss: 2.14640\n",
            "Epoch 16 | Worker: 2 | TRAIN: Last Loss: 2.11885\n",
            "Epoch 16 | Worker: 3 | TRAIN: Last Loss: 2.09754\n",
            "Epoch 16 | Worker: 4 | TRAIN: Last Loss: 2.12231\n",
            "Epoch 16 | Worker: 5 | TRAIN: Last Loss: 2.15283\n",
            "Epoch 16 | Worker: 6 | TRAIN: Last Loss: 2.12833\n",
            "Epoch 16 | Worker: 7 | TRAIN: Last Loss: 2.14657\n",
            "Epoch 16 | Worker: 8 | TRAIN: Last Loss: 2.14613\n",
            "Epoch 16 | Worker: 9 | TRAIN: Last Loss: 2.10635\n",
            "Last Loss: 2.1056 | Accuracy: 33.94% | Correct: 3394/10000 | Precision: 0.7375 | Recall: 0.3394 | F1-score: 0.2531\n",
            "Epoch 17 | Worker: 0 | TRAIN: Last Loss: 1.99032\n",
            "Epoch 17 | Worker: 1 | TRAIN: Last Loss: 2.05541\n",
            "Epoch 17 | Worker: 2 | TRAIN: Last Loss: 1.98974\n",
            "Epoch 17 | Worker: 3 | TRAIN: Last Loss: 1.98712\n",
            "Epoch 17 | Worker: 4 | TRAIN: Last Loss: 2.02993\n",
            "Epoch 17 | Worker: 5 | TRAIN: Last Loss: 2.03354\n",
            "Epoch 17 | Worker: 6 | TRAIN: Last Loss: 2.02731\n",
            "Epoch 17 | Worker: 7 | TRAIN: Last Loss: 2.04855\n",
            "Epoch 17 | Worker: 8 | TRAIN: Last Loss: 2.04927\n",
            "Epoch 17 | Worker: 9 | TRAIN: Last Loss: 2.01898\n",
            "Epoch 18 | Worker: 0 | TRAIN: Last Loss: 1.78613\n",
            "Epoch 18 | Worker: 1 | TRAIN: Last Loss: 1.88120\n",
            "Epoch 18 | Worker: 2 | TRAIN: Last Loss: 1.78845\n",
            "Epoch 18 | Worker: 3 | TRAIN: Last Loss: 1.77808\n",
            "Epoch 18 | Worker: 4 | TRAIN: Last Loss: 1.86720\n",
            "Epoch 18 | Worker: 5 | TRAIN: Last Loss: 1.86136\n",
            "Epoch 18 | Worker: 6 | TRAIN: Last Loss: 1.86034\n",
            "Epoch 18 | Worker: 7 | TRAIN: Last Loss: 1.87878\n",
            "Epoch 18 | Worker: 8 | TRAIN: Last Loss: 1.86144\n",
            "Epoch 18 | Worker: 9 | TRAIN: Last Loss: 1.80308\n",
            "Epoch 19 | Worker: 0 | TRAIN: Last Loss: 1.47095\n",
            "Epoch 19 | Worker: 1 | TRAIN: Last Loss: 1.58348\n",
            "Epoch 19 | Worker: 2 | TRAIN: Last Loss: 1.50376\n",
            "Epoch 19 | Worker: 3 | TRAIN: Last Loss: 1.47935\n",
            "Epoch 19 | Worker: 4 | TRAIN: Last Loss: 1.64745\n",
            "Epoch 19 | Worker: 5 | TRAIN: Last Loss: 1.58530\n",
            "Epoch 19 | Worker: 6 | TRAIN: Last Loss: 1.58144\n",
            "Epoch 19 | Worker: 7 | TRAIN: Last Loss: 1.59064\n",
            "Epoch 19 | Worker: 8 | TRAIN: Last Loss: 1.57760\n",
            "Epoch 19 | Worker: 9 | TRAIN: Last Loss: 1.50962\n",
            "Epoch 20 | Worker: 0 | TRAIN: Last Loss: 1.08069\n",
            "Epoch 20 | Worker: 1 | TRAIN: Last Loss: 1.17363\n",
            "Epoch 20 | Worker: 2 | TRAIN: Last Loss: 1.15042\n",
            "Epoch 20 | Worker: 3 | TRAIN: Last Loss: 1.11536\n",
            "Epoch 20 | Worker: 4 | TRAIN: Last Loss: 1.37978\n",
            "Epoch 20 | Worker: 5 | TRAIN: Last Loss: 1.22782\n",
            "Epoch 20 | Worker: 6 | TRAIN: Last Loss: 1.19798\n",
            "Epoch 20 | Worker: 7 | TRAIN: Last Loss: 1.18520\n",
            "Epoch 20 | Worker: 8 | TRAIN: Last Loss: 1.24812\n",
            "Epoch 20 | Worker: 9 | TRAIN: Last Loss: 1.15300\n",
            "Last Loss: 1.0500 | Accuracy: 69.08% | Correct: 6908/10000 | Precision: 0.7233 | Recall: 0.6908 | F1-score: 0.6419\n",
            "Quantidade de workers maliciosos: 3\n",
            "Epoch 1 | Worker: 0 | TRAIN: Last Loss: 2.26820\n",
            "Epoch 1 | Worker: 1 | TRAIN: Last Loss: 2.27497\n",
            "Epoch 1 | Worker: 2 | TRAIN: Last Loss: 2.27141\n",
            "Epoch 1 | Worker: 3 | TRAIN: Last Loss: 2.27601\n",
            "Epoch 1 | Worker: 4 | TRAIN: Last Loss: 2.27802\n",
            "Epoch 1 | Worker: 5 | TRAIN: Last Loss: 2.26311\n",
            "Epoch 1 | Worker: 6 | TRAIN: Last Loss: 2.28457\n",
            "Epoch 1 | Worker: 7 | TRAIN: Last Loss: 2.25954\n",
            "Epoch 1 | Worker: 8 | TRAIN: Last Loss: 2.26492\n",
            "Epoch 1 | Worker: 9 | TRAIN: Last Loss: 2.25948\n",
            "Epoch 2 | Worker: 0 | TRAIN: Last Loss: 2.30215\n",
            "Epoch 2 | Worker: 1 | TRAIN: Last Loss: 2.30118\n",
            "Epoch 2 | Worker: 2 | TRAIN: Last Loss: 2.30433\n",
            "Epoch 2 | Worker: 3 | TRAIN: Last Loss: 2.21862\n",
            "Epoch 2 | Worker: 4 | TRAIN: Last Loss: 2.17844\n",
            "Epoch 2 | Worker: 5 | TRAIN: Last Loss: 2.15908\n",
            "Epoch 2 | Worker: 6 | TRAIN: Last Loss: 2.26150\n",
            "Epoch 2 | Worker: 7 | TRAIN: Last Loss: 2.14449\n",
            "Epoch 2 | Worker: 8 | TRAIN: Last Loss: 2.18667\n",
            "Epoch 2 | Worker: 9 | TRAIN: Last Loss: 2.13582\n",
            "Epoch 3 | Worker: 0 | TRAIN: Last Loss: 2.30134\n",
            "Epoch 3 | Worker: 1 | TRAIN: Last Loss: 2.30505\n",
            "Epoch 3 | Worker: 2 | TRAIN: Last Loss: 2.30173\n",
            "Epoch 3 | Worker: 3 | TRAIN: Last Loss: 2.00987\n",
            "Epoch 3 | Worker: 4 | TRAIN: Last Loss: 1.69362\n",
            "Epoch 3 | Worker: 5 | TRAIN: Last Loss: 1.68594\n",
            "Epoch 3 | Worker: 6 | TRAIN: Last Loss: 2.20272\n",
            "Epoch 3 | Worker: 7 | TRAIN: Last Loss: 1.59357\n",
            "Epoch 3 | Worker: 8 | TRAIN: Last Loss: 1.85518\n",
            "Epoch 3 | Worker: 9 | TRAIN: Last Loss: 1.51828\n",
            "Epoch 4 | Worker: 0 | TRAIN: Last Loss: 2.29974\n",
            "Epoch 4 | Worker: 1 | TRAIN: Last Loss: 2.30580\n",
            "Epoch 4 | Worker: 2 | TRAIN: Last Loss: 2.30022\n",
            "Epoch 4 | Worker: 3 | TRAIN: Last Loss: 1.14342\n",
            "Epoch 4 | Worker: 4 | TRAIN: Last Loss: 1.02715\n",
            "Epoch 4 | Worker: 5 | TRAIN: Last Loss: 0.78611\n",
            "Epoch 4 | Worker: 6 | TRAIN: Last Loss: 1.96527\n",
            "Epoch 4 | Worker: 7 | TRAIN: Last Loss: 0.76489\n",
            "Epoch 4 | Worker: 8 | TRAIN: Last Loss: 1.01467\n",
            "Epoch 4 | Worker: 9 | TRAIN: Last Loss: 0.64378\n",
            "Last Loss: 2.2968 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Epoch 5 | Worker: 0 | TRAIN: Last Loss: 2.30192\n",
            "Epoch 5 | Worker: 1 | TRAIN: Last Loss: 2.29744\n",
            "Epoch 5 | Worker: 2 | TRAIN: Last Loss: 2.30490\n",
            "Epoch 5 | Worker: 3 | TRAIN: Last Loss: 2.30015\n",
            "Epoch 5 | Worker: 4 | TRAIN: Last Loss: 2.30234\n",
            "Epoch 5 | Worker: 5 | TRAIN: Last Loss: 2.30857\n",
            "Epoch 5 | Worker: 6 | TRAIN: Last Loss: 2.29699\n",
            "Epoch 5 | Worker: 7 | TRAIN: Last Loss: 2.29489\n",
            "Epoch 5 | Worker: 8 | TRAIN: Last Loss: 2.30597\n",
            "Epoch 5 | Worker: 9 | TRAIN: Last Loss: 2.30221\n",
            "Epoch 6 | Worker: 0 | TRAIN: Last Loss: 2.29976\n",
            "Epoch 6 | Worker: 1 | TRAIN: Last Loss: 2.29946\n",
            "Epoch 6 | Worker: 2 | TRAIN: Last Loss: 2.30260\n",
            "Epoch 6 | Worker: 3 | TRAIN: Last Loss: 2.29927\n",
            "Epoch 6 | Worker: 4 | TRAIN: Last Loss: 2.29961\n",
            "Epoch 6 | Worker: 5 | TRAIN: Last Loss: 2.30753\n",
            "Epoch 6 | Worker: 6 | TRAIN: Last Loss: 2.29743\n",
            "Epoch 6 | Worker: 7 | TRAIN: Last Loss: 2.29564\n",
            "Epoch 6 | Worker: 8 | TRAIN: Last Loss: 2.30571\n",
            "Epoch 6 | Worker: 9 | TRAIN: Last Loss: 2.30244\n",
            "Epoch 7 | Worker: 0 | TRAIN: Last Loss: 2.29829\n",
            "Epoch 7 | Worker: 1 | TRAIN: Last Loss: 2.30077\n",
            "Epoch 7 | Worker: 2 | TRAIN: Last Loss: 2.30105\n",
            "Epoch 7 | Worker: 3 | TRAIN: Last Loss: 2.29859\n",
            "Epoch 7 | Worker: 4 | TRAIN: Last Loss: 2.29767\n",
            "Epoch 7 | Worker: 5 | TRAIN: Last Loss: 2.30707\n",
            "Epoch 7 | Worker: 6 | TRAIN: Last Loss: 2.29760\n",
            "Epoch 7 | Worker: 7 | TRAIN: Last Loss: 2.29594\n",
            "Epoch 7 | Worker: 8 | TRAIN: Last Loss: 2.30560\n",
            "Epoch 7 | Worker: 9 | TRAIN: Last Loss: 2.30262\n",
            "Epoch 8 | Worker: 0 | TRAIN: Last Loss: 2.29721\n",
            "Epoch 8 | Worker: 1 | TRAIN: Last Loss: 2.30164\n",
            "Epoch 8 | Worker: 2 | TRAIN: Last Loss: 2.29989\n",
            "Epoch 8 | Worker: 3 | TRAIN: Last Loss: 2.29803\n",
            "Epoch 8 | Worker: 4 | TRAIN: Last Loss: 2.29619\n",
            "Epoch 8 | Worker: 5 | TRAIN: Last Loss: 2.30690\n",
            "Epoch 8 | Worker: 6 | TRAIN: Last Loss: 2.29761\n",
            "Epoch 8 | Worker: 7 | TRAIN: Last Loss: 2.29598\n",
            "Epoch 8 | Worker: 8 | TRAIN: Last Loss: 2.30555\n",
            "Epoch 8 | Worker: 9 | TRAIN: Last Loss: 2.30274\n",
            "Last Loss: 2.3011 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Epoch 9 | Worker: 0 | TRAIN: Last Loss: 2.29710\n",
            "Epoch 9 | Worker: 1 | TRAIN: Last Loss: 2.30272\n",
            "Epoch 9 | Worker: 2 | TRAIN: Last Loss: 2.29981\n",
            "Epoch 9 | Worker: 3 | TRAIN: Last Loss: 2.29757\n",
            "Epoch 9 | Worker: 4 | TRAIN: Last Loss: 2.29530\n",
            "Epoch 9 | Worker: 5 | TRAIN: Last Loss: 2.30538\n",
            "Epoch 9 | Worker: 6 | TRAIN: Last Loss: 2.29819\n",
            "Epoch 9 | Worker: 7 | TRAIN: Last Loss: 2.29663\n",
            "Epoch 9 | Worker: 8 | TRAIN: Last Loss: 2.30727\n",
            "Epoch 9 | Worker: 9 | TRAIN: Last Loss: 2.30176\n",
            "Epoch 10 | Worker: 0 | TRAIN: Last Loss: 2.29634\n",
            "Epoch 10 | Worker: 1 | TRAIN: Last Loss: 2.30312\n",
            "Epoch 10 | Worker: 2 | TRAIN: Last Loss: 2.29900\n",
            "Epoch 10 | Worker: 3 | TRAIN: Last Loss: 2.29719\n",
            "Epoch 10 | Worker: 4 | TRAIN: Last Loss: 2.29427\n",
            "Epoch 10 | Worker: 5 | TRAIN: Last Loss: 2.30568\n",
            "Epoch 10 | Worker: 6 | TRAIN: Last Loss: 2.29793\n",
            "Epoch 10 | Worker: 7 | TRAIN: Last Loss: 2.29649\n",
            "Epoch 10 | Worker: 8 | TRAIN: Last Loss: 2.30709\n",
            "Epoch 10 | Worker: 9 | TRAIN: Last Loss: 2.30196\n",
            "Epoch 11 | Worker: 0 | TRAIN: Last Loss: 2.29572\n",
            "Epoch 11 | Worker: 1 | TRAIN: Last Loss: 2.30342\n",
            "Epoch 11 | Worker: 2 | TRAIN: Last Loss: 2.29832\n",
            "Epoch 11 | Worker: 3 | TRAIN: Last Loss: 2.29684\n",
            "Epoch 11 | Worker: 4 | TRAIN: Last Loss: 2.29341\n",
            "Epoch 11 | Worker: 5 | TRAIN: Last Loss: 2.30600\n",
            "Epoch 11 | Worker: 6 | TRAIN: Last Loss: 2.29767\n",
            "Epoch 11 | Worker: 7 | TRAIN: Last Loss: 2.29627\n",
            "Epoch 11 | Worker: 8 | TRAIN: Last Loss: 2.30693\n",
            "Epoch 11 | Worker: 9 | TRAIN: Last Loss: 2.30211\n",
            "Epoch 12 | Worker: 0 | TRAIN: Last Loss: 2.29518\n",
            "Epoch 12 | Worker: 1 | TRAIN: Last Loss: 2.30364\n",
            "Epoch 12 | Worker: 2 | TRAIN: Last Loss: 2.29774\n",
            "Epoch 12 | Worker: 3 | TRAIN: Last Loss: 2.29653\n",
            "Epoch 12 | Worker: 4 | TRAIN: Last Loss: 2.29266\n",
            "Epoch 12 | Worker: 5 | TRAIN: Last Loss: 2.30630\n",
            "Epoch 12 | Worker: 6 | TRAIN: Last Loss: 2.29742\n",
            "Epoch 12 | Worker: 7 | TRAIN: Last Loss: 2.29603\n",
            "Epoch 12 | Worker: 8 | TRAIN: Last Loss: 2.30679\n",
            "Epoch 12 | Worker: 9 | TRAIN: Last Loss: 2.30222\n",
            "Last Loss: 2.3023 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Epoch 13 | Worker: 0 | TRAIN: Last Loss: 2.29543\n",
            "Epoch 13 | Worker: 1 | TRAIN: Last Loss: 2.30425\n",
            "Epoch 13 | Worker: 2 | TRAIN: Last Loss: 2.29806\n",
            "Epoch 13 | Worker: 3 | TRAIN: Last Loss: 2.29633\n",
            "Epoch 13 | Worker: 4 | TRAIN: Last Loss: 2.29233\n",
            "Epoch 13 | Worker: 5 | TRAIN: Last Loss: 2.30510\n",
            "Epoch 13 | Worker: 6 | TRAIN: Last Loss: 2.29786\n",
            "Epoch 13 | Worker: 7 | TRAIN: Last Loss: 2.29648\n",
            "Epoch 13 | Worker: 8 | TRAIN: Last Loss: 2.30844\n",
            "Epoch 13 | Worker: 9 | TRAIN: Last Loss: 2.30126\n",
            "Epoch 14 | Worker: 0 | TRAIN: Last Loss: 2.29496\n",
            "Epoch 14 | Worker: 1 | TRAIN: Last Loss: 2.30435\n",
            "Epoch 14 | Worker: 2 | TRAIN: Last Loss: 2.29754\n",
            "Epoch 14 | Worker: 3 | TRAIN: Last Loss: 2.29607\n",
            "Epoch 14 | Worker: 4 | TRAIN: Last Loss: 2.29171\n",
            "Epoch 14 | Worker: 5 | TRAIN: Last Loss: 2.30557\n",
            "Epoch 14 | Worker: 6 | TRAIN: Last Loss: 2.29752\n",
            "Epoch 14 | Worker: 7 | TRAIN: Last Loss: 2.29623\n",
            "Epoch 14 | Worker: 8 | TRAIN: Last Loss: 2.30816\n",
            "Epoch 14 | Worker: 9 | TRAIN: Last Loss: 2.30148\n",
            "Epoch 15 | Worker: 0 | TRAIN: Last Loss: 2.29455\n",
            "Epoch 15 | Worker: 1 | TRAIN: Last Loss: 2.30441\n",
            "Epoch 15 | Worker: 2 | TRAIN: Last Loss: 2.29709\n",
            "Epoch 15 | Worker: 3 | TRAIN: Last Loss: 2.29584\n",
            "Epoch 15 | Worker: 4 | TRAIN: Last Loss: 2.29117\n",
            "Epoch 15 | Worker: 5 | TRAIN: Last Loss: 2.30599\n",
            "Epoch 15 | Worker: 6 | TRAIN: Last Loss: 2.29721\n",
            "Epoch 15 | Worker: 7 | TRAIN: Last Loss: 2.29598\n",
            "Epoch 15 | Worker: 8 | TRAIN: Last Loss: 2.30791\n",
            "Epoch 15 | Worker: 9 | TRAIN: Last Loss: 2.30165\n",
            "Epoch 16 | Worker: 0 | TRAIN: Last Loss: 2.29418\n",
            "Epoch 16 | Worker: 1 | TRAIN: Last Loss: 2.30446\n",
            "Epoch 16 | Worker: 2 | TRAIN: Last Loss: 2.29669\n",
            "Epoch 16 | Worker: 3 | TRAIN: Last Loss: 2.29564\n",
            "Epoch 16 | Worker: 4 | TRAIN: Last Loss: 2.29069\n",
            "Epoch 16 | Worker: 5 | TRAIN: Last Loss: 2.30638\n",
            "Epoch 16 | Worker: 6 | TRAIN: Last Loss: 2.29695\n",
            "Epoch 16 | Worker: 7 | TRAIN: Last Loss: 2.29572\n",
            "Epoch 16 | Worker: 8 | TRAIN: Last Loss: 2.30768\n",
            "Epoch 16 | Worker: 9 | TRAIN: Last Loss: 2.30179\n",
            "Last Loss: 2.3028 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Epoch 17 | Worker: 0 | TRAIN: Last Loss: 2.29456\n",
            "Epoch 17 | Worker: 1 | TRAIN: Last Loss: 2.30493\n",
            "Epoch 17 | Worker: 2 | TRAIN: Last Loss: 2.29715\n",
            "Epoch 17 | Worker: 3 | TRAIN: Last Loss: 2.29555\n",
            "Epoch 17 | Worker: 4 | TRAIN: Last Loss: 2.29060\n",
            "Epoch 17 | Worker: 5 | TRAIN: Last Loss: 2.30522\n",
            "Epoch 17 | Worker: 6 | TRAIN: Last Loss: 2.29739\n",
            "Epoch 17 | Worker: 7 | TRAIN: Last Loss: 2.29615\n",
            "Epoch 17 | Worker: 8 | TRAIN: Last Loss: 2.30926\n",
            "Epoch 17 | Worker: 9 | TRAIN: Last Loss: 2.30088\n",
            "Epoch 18 | Worker: 0 | TRAIN: Last Loss: 2.29420\n",
            "Epoch 18 | Worker: 1 | TRAIN: Last Loss: 2.30491\n",
            "Epoch 18 | Worker: 2 | TRAIN: Last Loss: 2.29675\n",
            "Epoch 18 | Worker: 3 | TRAIN: Last Loss: 2.29537\n",
            "Epoch 18 | Worker: 4 | TRAIN: Last Loss: 2.29018\n",
            "Epoch 18 | Worker: 5 | TRAIN: Last Loss: 2.30573\n",
            "Epoch 18 | Worker: 6 | TRAIN: Last Loss: 2.29704\n",
            "Epoch 18 | Worker: 7 | TRAIN: Last Loss: 2.29592\n",
            "Epoch 18 | Worker: 8 | TRAIN: Last Loss: 2.30890\n",
            "Epoch 18 | Worker: 9 | TRAIN: Last Loss: 2.30112\n",
            "Epoch 19 | Worker: 0 | TRAIN: Last Loss: 2.29389\n",
            "Epoch 19 | Worker: 1 | TRAIN: Last Loss: 2.30490\n",
            "Epoch 19 | Worker: 2 | TRAIN: Last Loss: 2.29640\n",
            "Epoch 19 | Worker: 3 | TRAIN: Last Loss: 2.29521\n",
            "Epoch 19 | Worker: 4 | TRAIN: Last Loss: 2.28980\n",
            "Epoch 19 | Worker: 5 | TRAIN: Last Loss: 2.30617\n",
            "Epoch 19 | Worker: 6 | TRAIN: Last Loss: 2.29675\n",
            "Epoch 19 | Worker: 7 | TRAIN: Last Loss: 2.29568\n",
            "Epoch 19 | Worker: 8 | TRAIN: Last Loss: 2.30858\n",
            "Epoch 19 | Worker: 9 | TRAIN: Last Loss: 2.30132\n",
            "Epoch 20 | Worker: 0 | TRAIN: Last Loss: 2.29361\n",
            "Epoch 20 | Worker: 1 | TRAIN: Last Loss: 2.30487\n",
            "Epoch 20 | Worker: 2 | TRAIN: Last Loss: 2.29609\n",
            "Epoch 20 | Worker: 3 | TRAIN: Last Loss: 2.29507\n",
            "Epoch 20 | Worker: 4 | TRAIN: Last Loss: 2.28947\n",
            "Epoch 20 | Worker: 5 | TRAIN: Last Loss: 2.30656\n",
            "Epoch 20 | Worker: 6 | TRAIN: Last Loss: 2.29651\n",
            "Epoch 20 | Worker: 7 | TRAIN: Last Loss: 2.29544\n",
            "Epoch 20 | Worker: 8 | TRAIN: Last Loss: 2.30829\n",
            "Epoch 20 | Worker: 9 | TRAIN: Last Loss: 2.30149\n",
            "Last Loss: 2.3031 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Quantidade de workers maliciosos: 4\n",
            "Epoch 1 | Worker: 0 | TRAIN: Last Loss: 2.22293\n",
            "Epoch 1 | Worker: 1 | TRAIN: Last Loss: 2.27061\n",
            "Epoch 1 | Worker: 2 | TRAIN: Last Loss: 2.24572\n",
            "Epoch 1 | Worker: 3 | TRAIN: Last Loss: 2.24329\n",
            "Epoch 1 | Worker: 4 | TRAIN: Last Loss: 2.25785\n",
            "Epoch 1 | Worker: 5 | TRAIN: Last Loss: 2.27891\n",
            "Epoch 1 | Worker: 6 | TRAIN: Last Loss: 2.25782\n",
            "Epoch 1 | Worker: 7 | TRAIN: Last Loss: 2.27143\n",
            "Epoch 1 | Worker: 8 | TRAIN: Last Loss: 2.28183\n",
            "Epoch 1 | Worker: 9 | TRAIN: Last Loss: 2.23176\n",
            "Epoch 2 | Worker: 0 | TRAIN: Last Loss: 2.30045\n",
            "Epoch 2 | Worker: 1 | TRAIN: Last Loss: 2.30339\n",
            "Epoch 2 | Worker: 2 | TRAIN: Last Loss: 2.29950\n",
            "Epoch 2 | Worker: 3 | TRAIN: Last Loss: 2.30057\n",
            "Epoch 2 | Worker: 4 | TRAIN: Last Loss: 2.11890\n",
            "Epoch 2 | Worker: 5 | TRAIN: Last Loss: 2.20699\n",
            "Epoch 2 | Worker: 6 | TRAIN: Last Loss: 2.16276\n",
            "Epoch 2 | Worker: 7 | TRAIN: Last Loss: 2.17401\n",
            "Epoch 2 | Worker: 8 | TRAIN: Last Loss: 2.23373\n",
            "Epoch 2 | Worker: 9 | TRAIN: Last Loss: 1.94416\n",
            "Epoch 3 | Worker: 0 | TRAIN: Last Loss: 2.29931\n",
            "Epoch 3 | Worker: 1 | TRAIN: Last Loss: 2.30385\n",
            "Epoch 3 | Worker: 2 | TRAIN: Last Loss: 2.29856\n",
            "Epoch 3 | Worker: 3 | TRAIN: Last Loss: 2.29935\n",
            "Epoch 3 | Worker: 4 | TRAIN: Last Loss: 1.48694\n",
            "Epoch 3 | Worker: 5 | TRAIN: Last Loss: 1.91513\n",
            "Epoch 3 | Worker: 6 | TRAIN: Last Loss: 1.69367\n",
            "Epoch 3 | Worker: 7 | TRAIN: Last Loss: 1.75242\n",
            "Epoch 3 | Worker: 8 | TRAIN: Last Loss: 2.08898\n",
            "Epoch 3 | Worker: 9 | TRAIN: Last Loss: 0.99660\n",
            "Epoch 4 | Worker: 0 | TRAIN: Last Loss: 2.29853\n",
            "Epoch 4 | Worker: 1 | TRAIN: Last Loss: 2.30381\n",
            "Epoch 4 | Worker: 2 | TRAIN: Last Loss: 2.29800\n",
            "Epoch 4 | Worker: 3 | TRAIN: Last Loss: 2.29880\n",
            "Epoch 4 | Worker: 4 | TRAIN: Last Loss: 0.96800\n",
            "Epoch 4 | Worker: 5 | TRAIN: Last Loss: 1.01068\n",
            "Epoch 4 | Worker: 6 | TRAIN: Last Loss: 0.70962\n",
            "Epoch 4 | Worker: 7 | TRAIN: Last Loss: 0.90113\n",
            "Epoch 4 | Worker: 8 | TRAIN: Last Loss: 1.44586\n",
            "Epoch 4 | Worker: 9 | TRAIN: Last Loss: 0.58509\n",
            "Last Loss: 2.3195 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Epoch 5 | Worker: 0 | TRAIN: Last Loss: 2.29784\n",
            "Epoch 5 | Worker: 1 | TRAIN: Last Loss: 2.30208\n",
            "Epoch 5 | Worker: 2 | TRAIN: Last Loss: 2.29589\n",
            "Epoch 5 | Worker: 3 | TRAIN: Last Loss: 2.30192\n",
            "Epoch 5 | Worker: 4 | TRAIN: Last Loss: 2.29110\n",
            "Epoch 5 | Worker: 5 | TRAIN: Last Loss: 2.30247\n",
            "Epoch 5 | Worker: 6 | TRAIN: Last Loss: 2.30141\n",
            "Epoch 5 | Worker: 7 | TRAIN: Last Loss: 2.30149\n",
            "Epoch 5 | Worker: 8 | TRAIN: Last Loss: 2.30805\n",
            "Epoch 5 | Worker: 9 | TRAIN: Last Loss: 2.30498\n",
            "Epoch 6 | Worker: 0 | TRAIN: Last Loss: 2.29739\n",
            "Epoch 6 | Worker: 1 | TRAIN: Last Loss: 2.30280\n",
            "Epoch 6 | Worker: 2 | TRAIN: Last Loss: 2.29693\n",
            "Epoch 6 | Worker: 3 | TRAIN: Last Loss: 2.29958\n",
            "Epoch 6 | Worker: 4 | TRAIN: Last Loss: 2.29288\n",
            "Epoch 6 | Worker: 5 | TRAIN: Last Loss: 2.30432\n",
            "Epoch 6 | Worker: 6 | TRAIN: Last Loss: 2.29958\n",
            "Epoch 6 | Worker: 7 | TRAIN: Last Loss: 2.29743\n",
            "Epoch 6 | Worker: 8 | TRAIN: Last Loss: 2.30723\n",
            "Epoch 6 | Worker: 9 | TRAIN: Last Loss: 2.30306\n",
            "Epoch 7 | Worker: 0 | TRAIN: Last Loss: 2.29690\n",
            "Epoch 7 | Worker: 1 | TRAIN: Last Loss: 2.30309\n",
            "Epoch 7 | Worker: 2 | TRAIN: Last Loss: 2.29709\n",
            "Epoch 7 | Worker: 3 | TRAIN: Last Loss: 2.29854\n",
            "Epoch 7 | Worker: 4 | TRAIN: Last Loss: 2.29312\n",
            "Epoch 7 | Worker: 5 | TRAIN: Last Loss: 2.30524\n",
            "Epoch 7 | Worker: 6 | TRAIN: Last Loss: 2.29873\n",
            "Epoch 7 | Worker: 7 | TRAIN: Last Loss: 2.29587\n",
            "Epoch 7 | Worker: 8 | TRAIN: Last Loss: 2.30690\n",
            "Epoch 7 | Worker: 9 | TRAIN: Last Loss: 2.30245\n",
            "Epoch 8 | Worker: 0 | TRAIN: Last Loss: 2.29642\n",
            "Epoch 8 | Worker: 1 | TRAIN: Last Loss: 2.30326\n",
            "Epoch 8 | Worker: 2 | TRAIN: Last Loss: 2.29694\n",
            "Epoch 8 | Worker: 3 | TRAIN: Last Loss: 2.29789\n",
            "Epoch 8 | Worker: 4 | TRAIN: Last Loss: 2.29289\n",
            "Epoch 8 | Worker: 5 | TRAIN: Last Loss: 2.30583\n",
            "Epoch 8 | Worker: 6 | TRAIN: Last Loss: 2.29818\n",
            "Epoch 8 | Worker: 7 | TRAIN: Last Loss: 2.29506\n",
            "Epoch 8 | Worker: 8 | TRAIN: Last Loss: 2.30669\n",
            "Epoch 8 | Worker: 9 | TRAIN: Last Loss: 2.30219\n",
            "Last Loss: 2.3032 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Epoch 9 | Worker: 0 | TRAIN: Last Loss: 2.29653\n",
            "Epoch 9 | Worker: 1 | TRAIN: Last Loss: 2.30417\n",
            "Epoch 9 | Worker: 2 | TRAIN: Last Loss: 2.29733\n",
            "Epoch 9 | Worker: 3 | TRAIN: Last Loss: 2.29704\n",
            "Epoch 9 | Worker: 4 | TRAIN: Last Loss: 2.29270\n",
            "Epoch 9 | Worker: 5 | TRAIN: Last Loss: 2.30484\n",
            "Epoch 9 | Worker: 6 | TRAIN: Last Loss: 2.29849\n",
            "Epoch 9 | Worker: 7 | TRAIN: Last Loss: 2.29596\n",
            "Epoch 9 | Worker: 8 | TRAIN: Last Loss: 2.30827\n",
            "Epoch 9 | Worker: 9 | TRAIN: Last Loss: 2.30143\n",
            "Epoch 10 | Worker: 0 | TRAIN: Last Loss: 2.29599\n",
            "Epoch 10 | Worker: 1 | TRAIN: Last Loss: 2.30405\n",
            "Epoch 10 | Worker: 2 | TRAIN: Last Loss: 2.29680\n",
            "Epoch 10 | Worker: 3 | TRAIN: Last Loss: 2.29688\n",
            "Epoch 10 | Worker: 4 | TRAIN: Last Loss: 2.29235\n",
            "Epoch 10 | Worker: 5 | TRAIN: Last Loss: 2.30535\n",
            "Epoch 10 | Worker: 6 | TRAIN: Last Loss: 2.29799\n",
            "Epoch 10 | Worker: 7 | TRAIN: Last Loss: 2.29499\n",
            "Epoch 10 | Worker: 8 | TRAIN: Last Loss: 2.30796\n",
            "Epoch 10 | Worker: 9 | TRAIN: Last Loss: 2.30130\n",
            "Epoch 11 | Worker: 0 | TRAIN: Last Loss: 2.29553\n",
            "Epoch 11 | Worker: 1 | TRAIN: Last Loss: 2.30399\n",
            "Epoch 11 | Worker: 2 | TRAIN: Last Loss: 2.29639\n",
            "Epoch 11 | Worker: 3 | TRAIN: Last Loss: 2.29667\n",
            "Epoch 11 | Worker: 4 | TRAIN: Last Loss: 2.29187\n",
            "Epoch 11 | Worker: 5 | TRAIN: Last Loss: 2.30579\n",
            "Epoch 11 | Worker: 6 | TRAIN: Last Loss: 2.29760\n",
            "Epoch 11 | Worker: 7 | TRAIN: Last Loss: 2.29442\n",
            "Epoch 11 | Worker: 8 | TRAIN: Last Loss: 2.30770\n",
            "Epoch 11 | Worker: 9 | TRAIN: Last Loss: 2.30128\n",
            "Epoch 12 | Worker: 0 | TRAIN: Last Loss: 2.29513\n",
            "Epoch 12 | Worker: 1 | TRAIN: Last Loss: 2.30395\n",
            "Epoch 12 | Worker: 2 | TRAIN: Last Loss: 2.29607\n",
            "Epoch 12 | Worker: 3 | TRAIN: Last Loss: 2.29646\n",
            "Epoch 12 | Worker: 4 | TRAIN: Last Loss: 2.29143\n",
            "Epoch 12 | Worker: 5 | TRAIN: Last Loss: 2.30618\n",
            "Epoch 12 | Worker: 6 | TRAIN: Last Loss: 2.29729\n",
            "Epoch 12 | Worker: 7 | TRAIN: Last Loss: 2.29402\n",
            "Epoch 12 | Worker: 8 | TRAIN: Last Loss: 2.30748\n",
            "Epoch 12 | Worker: 9 | TRAIN: Last Loss: 2.30132\n",
            "Last Loss: 2.3032 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Epoch 13 | Worker: 0 | TRAIN: Last Loss: 2.29534\n",
            "Epoch 13 | Worker: 1 | TRAIN: Last Loss: 2.30479\n",
            "Epoch 13 | Worker: 2 | TRAIN: Last Loss: 2.29648\n",
            "Epoch 13 | Worker: 3 | TRAIN: Last Loss: 2.29581\n",
            "Epoch 13 | Worker: 4 | TRAIN: Last Loss: 2.29121\n",
            "Epoch 13 | Worker: 5 | TRAIN: Last Loss: 2.30504\n",
            "Epoch 13 | Worker: 6 | TRAIN: Last Loss: 2.29777\n",
            "Epoch 13 | Worker: 7 | TRAIN: Last Loss: 2.29529\n",
            "Epoch 13 | Worker: 8 | TRAIN: Last Loss: 2.30904\n",
            "Epoch 13 | Worker: 9 | TRAIN: Last Loss: 2.30078\n",
            "Epoch 14 | Worker: 0 | TRAIN: Last Loss: 2.29490\n",
            "Epoch 14 | Worker: 1 | TRAIN: Last Loss: 2.30459\n",
            "Epoch 14 | Worker: 2 | TRAIN: Last Loss: 2.29596\n",
            "Epoch 14 | Worker: 3 | TRAIN: Last Loss: 2.29586\n",
            "Epoch 14 | Worker: 4 | TRAIN: Last Loss: 2.29088\n",
            "Epoch 14 | Worker: 5 | TRAIN: Last Loss: 2.30550\n",
            "Epoch 14 | Worker: 6 | TRAIN: Last Loss: 2.29738\n",
            "Epoch 14 | Worker: 7 | TRAIN: Last Loss: 2.29451\n",
            "Epoch 14 | Worker: 8 | TRAIN: Last Loss: 2.30867\n",
            "Epoch 14 | Worker: 9 | TRAIN: Last Loss: 2.30077\n",
            "Epoch 15 | Worker: 0 | TRAIN: Last Loss: 2.29453\n",
            "Epoch 15 | Worker: 1 | TRAIN: Last Loss: 2.30443\n",
            "Epoch 15 | Worker: 2 | TRAIN: Last Loss: 2.29560\n",
            "Epoch 15 | Worker: 3 | TRAIN: Last Loss: 2.29583\n",
            "Epoch 15 | Worker: 4 | TRAIN: Last Loss: 2.29050\n",
            "Epoch 15 | Worker: 5 | TRAIN: Last Loss: 2.30591\n",
            "Epoch 15 | Worker: 6 | TRAIN: Last Loss: 2.29707\n",
            "Epoch 15 | Worker: 7 | TRAIN: Last Loss: 2.29403\n",
            "Epoch 15 | Worker: 8 | TRAIN: Last Loss: 2.30836\n",
            "Epoch 15 | Worker: 9 | TRAIN: Last Loss: 2.30084\n",
            "Epoch 16 | Worker: 0 | TRAIN: Last Loss: 2.29422\n",
            "Epoch 16 | Worker: 1 | TRAIN: Last Loss: 2.30435\n",
            "Epoch 16 | Worker: 2 | TRAIN: Last Loss: 2.29532\n",
            "Epoch 16 | Worker: 3 | TRAIN: Last Loss: 2.29572\n",
            "Epoch 16 | Worker: 4 | TRAIN: Last Loss: 2.29017\n",
            "Epoch 16 | Worker: 5 | TRAIN: Last Loss: 2.30629\n",
            "Epoch 16 | Worker: 6 | TRAIN: Last Loss: 2.29682\n",
            "Epoch 16 | Worker: 7 | TRAIN: Last Loss: 2.29371\n",
            "Epoch 16 | Worker: 8 | TRAIN: Last Loss: 2.30808\n",
            "Epoch 16 | Worker: 9 | TRAIN: Last Loss: 2.30094\n",
            "Last Loss: 2.3035 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Epoch 17 | Worker: 0 | TRAIN: Last Loss: 2.29452\n",
            "Epoch 17 | Worker: 1 | TRAIN: Last Loss: 2.30518\n",
            "Epoch 17 | Worker: 2 | TRAIN: Last Loss: 2.29580\n",
            "Epoch 17 | Worker: 3 | TRAIN: Last Loss: 2.29512\n",
            "Epoch 17 | Worker: 4 | TRAIN: Last Loss: 2.29006\n",
            "Epoch 17 | Worker: 5 | TRAIN: Last Loss: 2.30510\n",
            "Epoch 17 | Worker: 6 | TRAIN: Last Loss: 2.29738\n",
            "Epoch 17 | Worker: 7 | TRAIN: Last Loss: 2.29503\n",
            "Epoch 17 | Worker: 8 | TRAIN: Last Loss: 2.30960\n",
            "Epoch 17 | Worker: 9 | TRAIN: Last Loss: 2.30047\n",
            "Epoch 18 | Worker: 0 | TRAIN: Last Loss: 2.29415\n",
            "Epoch 18 | Worker: 1 | TRAIN: Last Loss: 2.30490\n",
            "Epoch 18 | Worker: 2 | TRAIN: Last Loss: 2.29534\n",
            "Epoch 18 | Worker: 3 | TRAIN: Last Loss: 2.29527\n",
            "Epoch 18 | Worker: 4 | TRAIN: Last Loss: 2.28982\n",
            "Epoch 18 | Worker: 5 | TRAIN: Last Loss: 2.30556\n",
            "Epoch 18 | Worker: 6 | TRAIN: Last Loss: 2.29700\n",
            "Epoch 18 | Worker: 7 | TRAIN: Last Loss: 2.29427\n",
            "Epoch 18 | Worker: 8 | TRAIN: Last Loss: 2.30919\n",
            "Epoch 18 | Worker: 9 | TRAIN: Last Loss: 2.30047\n",
            "Epoch 19 | Worker: 0 | TRAIN: Last Loss: 2.29386\n",
            "Epoch 19 | Worker: 1 | TRAIN: Last Loss: 2.30474\n",
            "Epoch 19 | Worker: 2 | TRAIN: Last Loss: 2.29503\n",
            "Epoch 19 | Worker: 3 | TRAIN: Last Loss: 2.29530\n",
            "Epoch 19 | Worker: 4 | TRAIN: Last Loss: 2.28954\n",
            "Epoch 19 | Worker: 5 | TRAIN: Last Loss: 2.30598\n",
            "Epoch 19 | Worker: 6 | TRAIN: Last Loss: 2.29673\n",
            "Epoch 19 | Worker: 7 | TRAIN: Last Loss: 2.29383\n",
            "Epoch 19 | Worker: 8 | TRAIN: Last Loss: 2.30882\n",
            "Epoch 19 | Worker: 9 | TRAIN: Last Loss: 2.30057\n",
            "Epoch 20 | Worker: 0 | TRAIN: Last Loss: 2.29361\n",
            "Epoch 20 | Worker: 1 | TRAIN: Last Loss: 2.30464\n",
            "Epoch 20 | Worker: 2 | TRAIN: Last Loss: 2.29480\n",
            "Epoch 20 | Worker: 3 | TRAIN: Last Loss: 2.29525\n",
            "Epoch 20 | Worker: 4 | TRAIN: Last Loss: 2.28928\n",
            "Epoch 20 | Worker: 5 | TRAIN: Last Loss: 2.30635\n",
            "Epoch 20 | Worker: 6 | TRAIN: Last Loss: 2.29652\n",
            "Epoch 20 | Worker: 7 | TRAIN: Last Loss: 2.29354\n",
            "Epoch 20 | Worker: 8 | TRAIN: Last Loss: 2.30850\n",
            "Epoch 20 | Worker: 9 | TRAIN: Last Loss: 2.30071\n",
            "Last Loss: 2.3037 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Quantidade de workers maliciosos: 5\n",
            "Epoch 1 | Worker: 0 | TRAIN: Last Loss: 2.25324\n",
            "Epoch 1 | Worker: 1 | TRAIN: Last Loss: 2.24333\n",
            "Epoch 1 | Worker: 2 | TRAIN: Last Loss: 2.24905\n",
            "Epoch 1 | Worker: 3 | TRAIN: Last Loss: 2.27749\n",
            "Epoch 1 | Worker: 4 | TRAIN: Last Loss: 2.26005\n",
            "Epoch 1 | Worker: 5 | TRAIN: Last Loss: 2.24560\n",
            "Epoch 1 | Worker: 6 | TRAIN: Last Loss: 2.26811\n",
            "Epoch 1 | Worker: 7 | TRAIN: Last Loss: 2.28820\n",
            "Epoch 1 | Worker: 8 | TRAIN: Last Loss: 2.26218\n",
            "Epoch 1 | Worker: 9 | TRAIN: Last Loss: 2.26636\n",
            "Epoch 2 | Worker: 0 | TRAIN: Last Loss: 2.30110\n",
            "Epoch 2 | Worker: 1 | TRAIN: Last Loss: 2.30198\n",
            "Epoch 2 | Worker: 2 | TRAIN: Last Loss: 2.29988\n",
            "Epoch 2 | Worker: 3 | TRAIN: Last Loss: 2.29982\n",
            "Epoch 2 | Worker: 4 | TRAIN: Last Loss: 2.29794\n",
            "Epoch 2 | Worker: 5 | TRAIN: Last Loss: 2.11478\n",
            "Epoch 2 | Worker: 6 | TRAIN: Last Loss: 2.18714\n",
            "Epoch 2 | Worker: 7 | TRAIN: Last Loss: 2.26108\n",
            "Epoch 2 | Worker: 8 | TRAIN: Last Loss: 2.15446\n",
            "Epoch 2 | Worker: 9 | TRAIN: Last Loss: 2.15804\n",
            "Epoch 3 | Worker: 0 | TRAIN: Last Loss: 2.29997\n",
            "Epoch 3 | Worker: 1 | TRAIN: Last Loss: 2.30259\n",
            "Epoch 3 | Worker: 2 | TRAIN: Last Loss: 2.29949\n",
            "Epoch 3 | Worker: 3 | TRAIN: Last Loss: 2.30000\n",
            "Epoch 3 | Worker: 4 | TRAIN: Last Loss: 2.29668\n",
            "Epoch 3 | Worker: 5 | TRAIN: Last Loss: 1.53038\n",
            "Epoch 3 | Worker: 6 | TRAIN: Last Loss: 1.79421\n",
            "Epoch 3 | Worker: 7 | TRAIN: Last Loss: 2.20190\n",
            "Epoch 3 | Worker: 8 | TRAIN: Last Loss: 1.62879\n",
            "Epoch 3 | Worker: 9 | TRAIN: Last Loss: 1.62500\n",
            "Epoch 4 | Worker: 0 | TRAIN: Last Loss: 2.29928\n",
            "Epoch 4 | Worker: 1 | TRAIN: Last Loss: 2.30271\n",
            "Epoch 4 | Worker: 2 | TRAIN: Last Loss: 2.29925\n",
            "Epoch 4 | Worker: 3 | TRAIN: Last Loss: 2.29941\n",
            "Epoch 4 | Worker: 4 | TRAIN: Last Loss: 2.29585\n",
            "Epoch 4 | Worker: 5 | TRAIN: Last Loss: 0.69306\n",
            "Epoch 4 | Worker: 6 | TRAIN: Last Loss: 0.83599\n",
            "Epoch 4 | Worker: 7 | TRAIN: Last Loss: 1.99422\n",
            "Epoch 4 | Worker: 8 | TRAIN: Last Loss: 0.87387\n",
            "Epoch 4 | Worker: 9 | TRAIN: Last Loss: 0.72691\n",
            "Last Loss: 2.2953 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Epoch 5 | Worker: 0 | TRAIN: Last Loss: 2.29660\n",
            "Epoch 5 | Worker: 1 | TRAIN: Last Loss: 2.30366\n",
            "Epoch 5 | Worker: 2 | TRAIN: Last Loss: 2.29866\n",
            "Epoch 5 | Worker: 3 | TRAIN: Last Loss: 2.29813\n",
            "Epoch 5 | Worker: 4 | TRAIN: Last Loss: 2.29275\n",
            "Epoch 5 | Worker: 5 | TRAIN: Last Loss: 2.31236\n",
            "Epoch 5 | Worker: 6 | TRAIN: Last Loss: 2.29813\n",
            "Epoch 5 | Worker: 7 | TRAIN: Last Loss: 2.29677\n",
            "Epoch 5 | Worker: 8 | TRAIN: Last Loss: 2.30555\n",
            "Epoch 5 | Worker: 9 | TRAIN: Last Loss: 2.29988\n",
            "Epoch 6 | Worker: 0 | TRAIN: Last Loss: 2.29710\n",
            "Epoch 6 | Worker: 1 | TRAIN: Last Loss: 2.30378\n",
            "Epoch 6 | Worker: 2 | TRAIN: Last Loss: 2.29910\n",
            "Epoch 6 | Worker: 3 | TRAIN: Last Loss: 2.29785\n",
            "Epoch 6 | Worker: 4 | TRAIN: Last Loss: 2.29380\n",
            "Epoch 6 | Worker: 5 | TRAIN: Last Loss: 2.30965\n",
            "Epoch 6 | Worker: 6 | TRAIN: Last Loss: 2.29882\n",
            "Epoch 6 | Worker: 7 | TRAIN: Last Loss: 2.29613\n",
            "Epoch 6 | Worker: 8 | TRAIN: Last Loss: 2.30578\n",
            "Epoch 6 | Worker: 9 | TRAIN: Last Loss: 2.30082\n",
            "Epoch 7 | Worker: 0 | TRAIN: Last Loss: 2.29686\n",
            "Epoch 7 | Worker: 1 | TRAIN: Last Loss: 2.30386\n",
            "Epoch 7 | Worker: 2 | TRAIN: Last Loss: 2.29895\n",
            "Epoch 7 | Worker: 3 | TRAIN: Last Loss: 2.29751\n",
            "Epoch 7 | Worker: 4 | TRAIN: Last Loss: 2.29353\n",
            "Epoch 7 | Worker: 5 | TRAIN: Last Loss: 2.30892\n",
            "Epoch 7 | Worker: 6 | TRAIN: Last Loss: 2.29883\n",
            "Epoch 7 | Worker: 7 | TRAIN: Last Loss: 2.29570\n",
            "Epoch 7 | Worker: 8 | TRAIN: Last Loss: 2.30588\n",
            "Epoch 7 | Worker: 9 | TRAIN: Last Loss: 2.30120\n",
            "Epoch 8 | Worker: 0 | TRAIN: Last Loss: 2.29648\n",
            "Epoch 8 | Worker: 1 | TRAIN: Last Loss: 2.30392\n",
            "Epoch 8 | Worker: 2 | TRAIN: Last Loss: 2.29867\n",
            "Epoch 8 | Worker: 3 | TRAIN: Last Loss: 2.29718\n",
            "Epoch 8 | Worker: 4 | TRAIN: Last Loss: 2.29300\n",
            "Epoch 8 | Worker: 5 | TRAIN: Last Loss: 2.30873\n",
            "Epoch 8 | Worker: 6 | TRAIN: Last Loss: 2.29861\n",
            "Epoch 8 | Worker: 7 | TRAIN: Last Loss: 2.29534\n",
            "Epoch 8 | Worker: 8 | TRAIN: Last Loss: 2.30589\n",
            "Epoch 8 | Worker: 9 | TRAIN: Last Loss: 2.30143\n",
            "Last Loss: 2.3015 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Epoch 9 | Worker: 0 | TRAIN: Last Loss: 2.29663\n",
            "Epoch 9 | Worker: 1 | TRAIN: Last Loss: 2.30448\n",
            "Epoch 9 | Worker: 2 | TRAIN: Last Loss: 2.29859\n",
            "Epoch 9 | Worker: 3 | TRAIN: Last Loss: 2.29694\n",
            "Epoch 9 | Worker: 4 | TRAIN: Last Loss: 2.29327\n",
            "Epoch 9 | Worker: 5 | TRAIN: Last Loss: 2.30712\n",
            "Epoch 9 | Worker: 6 | TRAIN: Last Loss: 2.29877\n",
            "Epoch 9 | Worker: 7 | TRAIN: Last Loss: 2.29594\n",
            "Epoch 9 | Worker: 8 | TRAIN: Last Loss: 2.30745\n",
            "Epoch 9 | Worker: 9 | TRAIN: Last Loss: 2.30061\n",
            "Epoch 10 | Worker: 0 | TRAIN: Last Loss: 2.29611\n",
            "Epoch 10 | Worker: 1 | TRAIN: Last Loss: 2.30447\n",
            "Epoch 10 | Worker: 2 | TRAIN: Last Loss: 2.29819\n",
            "Epoch 10 | Worker: 3 | TRAIN: Last Loss: 2.29663\n",
            "Epoch 10 | Worker: 4 | TRAIN: Last Loss: 2.29244\n",
            "Epoch 10 | Worker: 5 | TRAIN: Last Loss: 2.30767\n",
            "Epoch 10 | Worker: 6 | TRAIN: Last Loss: 2.29865\n",
            "Epoch 10 | Worker: 7 | TRAIN: Last Loss: 2.29557\n",
            "Epoch 10 | Worker: 8 | TRAIN: Last Loss: 2.30733\n",
            "Epoch 10 | Worker: 9 | TRAIN: Last Loss: 2.30082\n",
            "Epoch 11 | Worker: 0 | TRAIN: Last Loss: 2.29565\n",
            "Epoch 11 | Worker: 1 | TRAIN: Last Loss: 2.30446\n",
            "Epoch 11 | Worker: 2 | TRAIN: Last Loss: 2.29785\n",
            "Epoch 11 | Worker: 3 | TRAIN: Last Loss: 2.29636\n",
            "Epoch 11 | Worker: 4 | TRAIN: Last Loss: 2.29172\n",
            "Epoch 11 | Worker: 5 | TRAIN: Last Loss: 2.30804\n",
            "Epoch 11 | Worker: 6 | TRAIN: Last Loss: 2.29842\n",
            "Epoch 11 | Worker: 7 | TRAIN: Last Loss: 2.29524\n",
            "Epoch 11 | Worker: 8 | TRAIN: Last Loss: 2.30720\n",
            "Epoch 11 | Worker: 9 | TRAIN: Last Loss: 2.30100\n",
            "Epoch 12 | Worker: 0 | TRAIN: Last Loss: 2.29526\n",
            "Epoch 12 | Worker: 1 | TRAIN: Last Loss: 2.30446\n",
            "Epoch 12 | Worker: 2 | TRAIN: Last Loss: 2.29755\n",
            "Epoch 12 | Worker: 3 | TRAIN: Last Loss: 2.29612\n",
            "Epoch 12 | Worker: 4 | TRAIN: Last Loss: 2.29113\n",
            "Epoch 12 | Worker: 5 | TRAIN: Last Loss: 2.30830\n",
            "Epoch 12 | Worker: 6 | TRAIN: Last Loss: 2.29815\n",
            "Epoch 12 | Worker: 7 | TRAIN: Last Loss: 2.29495\n",
            "Epoch 12 | Worker: 8 | TRAIN: Last Loss: 2.30706\n",
            "Epoch 12 | Worker: 9 | TRAIN: Last Loss: 2.30115\n",
            "Last Loss: 2.3021 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Epoch 13 | Worker: 0 | TRAIN: Last Loss: 2.29547\n",
            "Epoch 13 | Worker: 1 | TRAIN: Last Loss: 2.30498\n",
            "Epoch 13 | Worker: 2 | TRAIN: Last Loss: 2.29752\n",
            "Epoch 13 | Worker: 3 | TRAIN: Last Loss: 2.29597\n",
            "Epoch 13 | Worker: 4 | TRAIN: Last Loss: 2.29146\n",
            "Epoch 13 | Worker: 5 | TRAIN: Last Loss: 2.30677\n",
            "Epoch 13 | Worker: 6 | TRAIN: Last Loss: 2.29826\n",
            "Epoch 13 | Worker: 7 | TRAIN: Last Loss: 2.29562\n",
            "Epoch 13 | Worker: 8 | TRAIN: Last Loss: 2.30848\n",
            "Epoch 13 | Worker: 9 | TRAIN: Last Loss: 2.30029\n",
            "Epoch 14 | Worker: 0 | TRAIN: Last Loss: 2.29503\n",
            "Epoch 14 | Worker: 1 | TRAIN: Last Loss: 2.30492\n",
            "Epoch 14 | Worker: 2 | TRAIN: Last Loss: 2.29720\n",
            "Epoch 14 | Worker: 3 | TRAIN: Last Loss: 2.29575\n",
            "Epoch 14 | Worker: 4 | TRAIN: Last Loss: 2.29074\n",
            "Epoch 14 | Worker: 5 | TRAIN: Last Loss: 2.30743\n",
            "Epoch 14 | Worker: 6 | TRAIN: Last Loss: 2.29819\n",
            "Epoch 14 | Worker: 7 | TRAIN: Last Loss: 2.29529\n",
            "Epoch 14 | Worker: 8 | TRAIN: Last Loss: 2.30827\n",
            "Epoch 14 | Worker: 9 | TRAIN: Last Loss: 2.30051\n",
            "Epoch 15 | Worker: 0 | TRAIN: Last Loss: 2.29466\n",
            "Epoch 15 | Worker: 1 | TRAIN: Last Loss: 2.30488\n",
            "Epoch 15 | Worker: 2 | TRAIN: Last Loss: 2.29694\n",
            "Epoch 15 | Worker: 3 | TRAIN: Last Loss: 2.29557\n",
            "Epoch 15 | Worker: 4 | TRAIN: Last Loss: 2.29017\n",
            "Epoch 15 | Worker: 5 | TRAIN: Last Loss: 2.30787\n",
            "Epoch 15 | Worker: 6 | TRAIN: Last Loss: 2.29802\n",
            "Epoch 15 | Worker: 7 | TRAIN: Last Loss: 2.29501\n",
            "Epoch 15 | Worker: 8 | TRAIN: Last Loss: 2.30805\n",
            "Epoch 15 | Worker: 9 | TRAIN: Last Loss: 2.30071\n",
            "Epoch 16 | Worker: 0 | TRAIN: Last Loss: 2.29435\n",
            "Epoch 16 | Worker: 1 | TRAIN: Last Loss: 2.30484\n",
            "Epoch 16 | Worker: 2 | TRAIN: Last Loss: 2.29672\n",
            "Epoch 16 | Worker: 3 | TRAIN: Last Loss: 2.29540\n",
            "Epoch 16 | Worker: 4 | TRAIN: Last Loss: 2.28972\n",
            "Epoch 16 | Worker: 5 | TRAIN: Last Loss: 2.30819\n",
            "Epoch 16 | Worker: 6 | TRAIN: Last Loss: 2.29778\n",
            "Epoch 16 | Worker: 7 | TRAIN: Last Loss: 2.29476\n",
            "Epoch 16 | Worker: 8 | TRAIN: Last Loss: 2.30783\n",
            "Epoch 16 | Worker: 9 | TRAIN: Last Loss: 2.30089\n",
            "Last Loss: 2.3025 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Epoch 17 | Worker: 0 | TRAIN: Last Loss: 2.29464\n",
            "Epoch 17 | Worker: 1 | TRAIN: Last Loss: 2.30534\n",
            "Epoch 17 | Worker: 2 | TRAIN: Last Loss: 2.29676\n",
            "Epoch 17 | Worker: 3 | TRAIN: Last Loss: 2.29533\n",
            "Epoch 17 | Worker: 4 | TRAIN: Last Loss: 2.29015\n",
            "Epoch 17 | Worker: 5 | TRAIN: Last Loss: 2.30671\n",
            "Epoch 17 | Worker: 6 | TRAIN: Last Loss: 2.29789\n",
            "Epoch 17 | Worker: 7 | TRAIN: Last Loss: 2.29545\n",
            "Epoch 17 | Worker: 8 | TRAIN: Last Loss: 2.30918\n",
            "Epoch 17 | Worker: 9 | TRAIN: Last Loss: 2.30007\n",
            "Epoch 18 | Worker: 0 | TRAIN: Last Loss: 2.29427\n",
            "Epoch 18 | Worker: 1 | TRAIN: Last Loss: 2.30525\n",
            "Epoch 18 | Worker: 2 | TRAIN: Last Loss: 2.29651\n",
            "Epoch 18 | Worker: 3 | TRAIN: Last Loss: 2.29517\n",
            "Epoch 18 | Worker: 4 | TRAIN: Last Loss: 2.28956\n",
            "Epoch 18 | Worker: 5 | TRAIN: Last Loss: 2.30738\n",
            "Epoch 18 | Worker: 6 | TRAIN: Last Loss: 2.29789\n",
            "Epoch 18 | Worker: 7 | TRAIN: Last Loss: 2.29516\n",
            "Epoch 18 | Worker: 8 | TRAIN: Last Loss: 2.30892\n",
            "Epoch 18 | Worker: 9 | TRAIN: Last Loss: 2.30031\n",
            "Epoch 19 | Worker: 0 | TRAIN: Last Loss: 2.29397\n",
            "Epoch 19 | Worker: 1 | TRAIN: Last Loss: 2.30517\n",
            "Epoch 19 | Worker: 2 | TRAIN: Last Loss: 2.29632\n",
            "Epoch 19 | Worker: 3 | TRAIN: Last Loss: 2.29504\n",
            "Epoch 19 | Worker: 4 | TRAIN: Last Loss: 2.28911\n",
            "Epoch 19 | Worker: 5 | TRAIN: Last Loss: 2.30784\n",
            "Epoch 19 | Worker: 6 | TRAIN: Last Loss: 2.29772\n",
            "Epoch 19 | Worker: 7 | TRAIN: Last Loss: 2.29490\n",
            "Epoch 19 | Worker: 8 | TRAIN: Last Loss: 2.30864\n",
            "Epoch 19 | Worker: 9 | TRAIN: Last Loss: 2.30053\n",
            "Epoch 20 | Worker: 0 | TRAIN: Last Loss: 2.29373\n",
            "Epoch 20 | Worker: 1 | TRAIN: Last Loss: 2.30511\n",
            "Epoch 20 | Worker: 2 | TRAIN: Last Loss: 2.29615\n",
            "Epoch 20 | Worker: 3 | TRAIN: Last Loss: 2.29493\n",
            "Epoch 20 | Worker: 4 | TRAIN: Last Loss: 2.28876\n",
            "Epoch 20 | Worker: 5 | TRAIN: Last Loss: 2.30817\n",
            "Epoch 20 | Worker: 6 | TRAIN: Last Loss: 2.29755\n",
            "Epoch 20 | Worker: 7 | TRAIN: Last Loss: 2.29467\n",
            "Epoch 20 | Worker: 8 | TRAIN: Last Loss: 2.30837\n",
            "Epoch 20 | Worker: 9 | TRAIN: Last Loss: 2.30072\n",
            "Last Loss: 2.3028 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Quantidade de workers maliciosos: 6\n",
            "Epoch 1 | Worker: 0 | TRAIN: Last Loss: 2.27260\n",
            "Epoch 1 | Worker: 1 | TRAIN: Last Loss: 2.28790\n",
            "Epoch 1 | Worker: 2 | TRAIN: Last Loss: 2.26855\n",
            "Epoch 1 | Worker: 3 | TRAIN: Last Loss: 2.26431\n",
            "Epoch 1 | Worker: 4 | TRAIN: Last Loss: 2.28705\n",
            "Epoch 1 | Worker: 5 | TRAIN: Last Loss: 2.27582\n",
            "Epoch 1 | Worker: 6 | TRAIN: Last Loss: 2.24255\n",
            "Epoch 1 | Worker: 7 | TRAIN: Last Loss: 2.25251\n",
            "Epoch 1 | Worker: 8 | TRAIN: Last Loss: 2.26885\n",
            "Epoch 1 | Worker: 9 | TRAIN: Last Loss: 2.26649\n",
            "Epoch 2 | Worker: 0 | TRAIN: Last Loss: 2.29960\n",
            "Epoch 2 | Worker: 1 | TRAIN: Last Loss: 2.30729\n",
            "Epoch 2 | Worker: 2 | TRAIN: Last Loss: 2.29904\n",
            "Epoch 2 | Worker: 3 | TRAIN: Last Loss: 2.30168\n",
            "Epoch 2 | Worker: 4 | TRAIN: Last Loss: 2.29854\n",
            "Epoch 2 | Worker: 5 | TRAIN: Last Loss: 2.30272\n",
            "Epoch 2 | Worker: 6 | TRAIN: Last Loss: 2.07897\n",
            "Epoch 2 | Worker: 7 | TRAIN: Last Loss: 2.11048\n",
            "Epoch 2 | Worker: 8 | TRAIN: Last Loss: 2.19091\n",
            "Epoch 2 | Worker: 9 | TRAIN: Last Loss: 2.17840\n",
            "Epoch 3 | Worker: 0 | TRAIN: Last Loss: 2.30040\n",
            "Epoch 3 | Worker: 1 | TRAIN: Last Loss: 2.30295\n",
            "Epoch 3 | Worker: 2 | TRAIN: Last Loss: 2.29857\n",
            "Epoch 3 | Worker: 3 | TRAIN: Last Loss: 2.30089\n",
            "Epoch 3 | Worker: 4 | TRAIN: Last Loss: 2.29812\n",
            "Epoch 3 | Worker: 5 | TRAIN: Last Loss: 2.30256\n",
            "Epoch 3 | Worker: 6 | TRAIN: Last Loss: 1.21031\n",
            "Epoch 3 | Worker: 7 | TRAIN: Last Loss: 1.47107\n",
            "Epoch 3 | Worker: 8 | TRAIN: Last Loss: 1.86103\n",
            "Epoch 3 | Worker: 9 | TRAIN: Last Loss: 1.76333\n",
            "Epoch 4 | Worker: 0 | TRAIN: Last Loss: 2.29960\n",
            "Epoch 4 | Worker: 1 | TRAIN: Last Loss: 2.30309\n",
            "Epoch 4 | Worker: 2 | TRAIN: Last Loss: 2.29809\n",
            "Epoch 4 | Worker: 3 | TRAIN: Last Loss: 2.30015\n",
            "Epoch 4 | Worker: 4 | TRAIN: Last Loss: 2.29693\n",
            "Epoch 4 | Worker: 5 | TRAIN: Last Loss: 2.30293\n",
            "Epoch 4 | Worker: 6 | TRAIN: Last Loss: 0.55296\n",
            "Epoch 4 | Worker: 7 | TRAIN: Last Loss: 0.69556\n",
            "Epoch 4 | Worker: 8 | TRAIN: Last Loss: 1.01391\n",
            "Epoch 4 | Worker: 9 | TRAIN: Last Loss: 0.74748\n",
            "Last Loss: 2.3285 | Accuracy: 9.82% | Correct: 982/10000 | Precision: 0.9114 | Recall: 0.0982 | F1-score: 0.0176\n",
            "Epoch 5 | Worker: 0 | TRAIN: Last Loss: 2.29764\n",
            "Epoch 5 | Worker: 1 | TRAIN: Last Loss: 2.30249\n",
            "Epoch 5 | Worker: 2 | TRAIN: Last Loss: 2.29773\n",
            "Epoch 5 | Worker: 3 | TRAIN: Last Loss: 2.29946\n",
            "Epoch 5 | Worker: 4 | TRAIN: Last Loss: 2.29436\n",
            "Epoch 5 | Worker: 5 | TRAIN: Last Loss: 2.30477\n",
            "Epoch 5 | Worker: 6 | TRAIN: Last Loss: 2.30011\n",
            "Epoch 5 | Worker: 7 | TRAIN: Last Loss: 2.29840\n",
            "Epoch 5 | Worker: 8 | TRAIN: Last Loss: 2.30707\n",
            "Epoch 5 | Worker: 9 | TRAIN: Last Loss: 2.30335\n",
            "Epoch 6 | Worker: 0 | TRAIN: Last Loss: 2.29730\n",
            "Epoch 6 | Worker: 1 | TRAIN: Last Loss: 2.30348\n",
            "Epoch 6 | Worker: 2 | TRAIN: Last Loss: 2.29800\n",
            "Epoch 6 | Worker: 3 | TRAIN: Last Loss: 2.29851\n",
            "Epoch 6 | Worker: 4 | TRAIN: Last Loss: 2.29428\n",
            "Epoch 6 | Worker: 5 | TRAIN: Last Loss: 2.30528\n",
            "Epoch 6 | Worker: 6 | TRAIN: Last Loss: 2.29919\n",
            "Epoch 6 | Worker: 7 | TRAIN: Last Loss: 2.29685\n",
            "Epoch 6 | Worker: 8 | TRAIN: Last Loss: 2.30680\n",
            "Epoch 6 | Worker: 9 | TRAIN: Last Loss: 2.30258\n",
            "Epoch 7 | Worker: 0 | TRAIN: Last Loss: 2.29684\n",
            "Epoch 7 | Worker: 1 | TRAIN: Last Loss: 2.30364\n",
            "Epoch 7 | Worker: 2 | TRAIN: Last Loss: 2.29770\n",
            "Epoch 7 | Worker: 3 | TRAIN: Last Loss: 2.29798\n",
            "Epoch 7 | Worker: 4 | TRAIN: Last Loss: 2.29363\n",
            "Epoch 7 | Worker: 5 | TRAIN: Last Loss: 2.30553\n",
            "Epoch 7 | Worker: 6 | TRAIN: Last Loss: 2.29868\n",
            "Epoch 7 | Worker: 7 | TRAIN: Last Loss: 2.29633\n",
            "Epoch 7 | Worker: 8 | TRAIN: Last Loss: 2.30663\n",
            "Epoch 7 | Worker: 9 | TRAIN: Last Loss: 2.30233\n",
            "Epoch 8 | Worker: 0 | TRAIN: Last Loss: 2.29639\n",
            "Epoch 8 | Worker: 1 | TRAIN: Last Loss: 2.30380\n",
            "Epoch 8 | Worker: 2 | TRAIN: Last Loss: 2.29735\n",
            "Epoch 8 | Worker: 3 | TRAIN: Last Loss: 2.29755\n",
            "Epoch 8 | Worker: 4 | TRAIN: Last Loss: 2.29285\n",
            "Epoch 8 | Worker: 5 | TRAIN: Last Loss: 2.30566\n",
            "Epoch 8 | Worker: 6 | TRAIN: Last Loss: 2.29827\n",
            "Epoch 8 | Worker: 7 | TRAIN: Last Loss: 2.29591\n",
            "Epoch 8 | Worker: 8 | TRAIN: Last Loss: 2.30650\n",
            "Epoch 8 | Worker: 9 | TRAIN: Last Loss: 2.30230\n",
            "Last Loss: 2.3028 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Epoch 9 | Worker: 0 | TRAIN: Last Loss: 2.29628\n",
            "Epoch 9 | Worker: 1 | TRAIN: Last Loss: 2.30446\n",
            "Epoch 9 | Worker: 2 | TRAIN: Last Loss: 2.29740\n",
            "Epoch 9 | Worker: 3 | TRAIN: Last Loss: 2.29709\n",
            "Epoch 9 | Worker: 4 | TRAIN: Last Loss: 2.29308\n",
            "Epoch 9 | Worker: 5 | TRAIN: Last Loss: 2.30539\n",
            "Epoch 9 | Worker: 6 | TRAIN: Last Loss: 2.29861\n",
            "Epoch 9 | Worker: 7 | TRAIN: Last Loss: 2.29621\n",
            "Epoch 9 | Worker: 8 | TRAIN: Last Loss: 2.30803\n",
            "Epoch 9 | Worker: 9 | TRAIN: Last Loss: 2.30152\n",
            "Epoch 10 | Worker: 0 | TRAIN: Last Loss: 2.29583\n",
            "Epoch 10 | Worker: 1 | TRAIN: Last Loss: 2.30439\n",
            "Epoch 10 | Worker: 2 | TRAIN: Last Loss: 2.29695\n",
            "Epoch 10 | Worker: 3 | TRAIN: Last Loss: 2.29682\n",
            "Epoch 10 | Worker: 4 | TRAIN: Last Loss: 2.29231\n",
            "Epoch 10 | Worker: 5 | TRAIN: Last Loss: 2.30540\n",
            "Epoch 10 | Worker: 6 | TRAIN: Last Loss: 2.29816\n",
            "Epoch 10 | Worker: 7 | TRAIN: Last Loss: 2.29566\n",
            "Epoch 10 | Worker: 8 | TRAIN: Last Loss: 2.30777\n",
            "Epoch 10 | Worker: 9 | TRAIN: Last Loss: 2.30140\n",
            "Epoch 11 | Worker: 0 | TRAIN: Last Loss: 2.29545\n",
            "Epoch 11 | Worker: 1 | TRAIN: Last Loss: 2.30438\n",
            "Epoch 11 | Worker: 2 | TRAIN: Last Loss: 2.29663\n",
            "Epoch 11 | Worker: 3 | TRAIN: Last Loss: 2.29658\n",
            "Epoch 11 | Worker: 4 | TRAIN: Last Loss: 2.29162\n",
            "Epoch 11 | Worker: 5 | TRAIN: Last Loss: 2.30547\n",
            "Epoch 11 | Worker: 6 | TRAIN: Last Loss: 2.29781\n",
            "Epoch 11 | Worker: 7 | TRAIN: Last Loss: 2.29532\n",
            "Epoch 11 | Worker: 8 | TRAIN: Last Loss: 2.30754\n",
            "Epoch 11 | Worker: 9 | TRAIN: Last Loss: 2.30143\n",
            "Epoch 12 | Worker: 0 | TRAIN: Last Loss: 2.29511\n",
            "Epoch 12 | Worker: 1 | TRAIN: Last Loss: 2.30438\n",
            "Epoch 12 | Worker: 2 | TRAIN: Last Loss: 2.29636\n",
            "Epoch 12 | Worker: 3 | TRAIN: Last Loss: 2.29636\n",
            "Epoch 12 | Worker: 4 | TRAIN: Last Loss: 2.29100\n",
            "Epoch 12 | Worker: 5 | TRAIN: Last Loss: 2.30556\n",
            "Epoch 12 | Worker: 6 | TRAIN: Last Loss: 2.29750\n",
            "Epoch 12 | Worker: 7 | TRAIN: Last Loss: 2.29502\n",
            "Epoch 12 | Worker: 8 | TRAIN: Last Loss: 2.30734\n",
            "Epoch 12 | Worker: 9 | TRAIN: Last Loss: 2.30151\n",
            "Last Loss: 2.3031 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Epoch 13 | Worker: 0 | TRAIN: Last Loss: 2.29511\n",
            "Epoch 13 | Worker: 1 | TRAIN: Last Loss: 2.30497\n",
            "Epoch 13 | Worker: 2 | TRAIN: Last Loss: 2.29649\n",
            "Epoch 13 | Worker: 3 | TRAIN: Last Loss: 2.29602\n",
            "Epoch 13 | Worker: 4 | TRAIN: Last Loss: 2.29140\n",
            "Epoch 13 | Worker: 5 | TRAIN: Last Loss: 2.30532\n",
            "Epoch 13 | Worker: 6 | TRAIN: Last Loss: 2.29796\n",
            "Epoch 13 | Worker: 7 | TRAIN: Last Loss: 2.29556\n",
            "Epoch 13 | Worker: 8 | TRAIN: Last Loss: 2.30882\n",
            "Epoch 13 | Worker: 9 | TRAIN: Last Loss: 2.30088\n",
            "Epoch 14 | Worker: 0 | TRAIN: Last Loss: 2.29477\n",
            "Epoch 14 | Worker: 1 | TRAIN: Last Loss: 2.30481\n",
            "Epoch 14 | Worker: 2 | TRAIN: Last Loss: 2.29611\n",
            "Epoch 14 | Worker: 3 | TRAIN: Last Loss: 2.29590\n",
            "Epoch 14 | Worker: 4 | TRAIN: Last Loss: 2.29073\n",
            "Epoch 14 | Worker: 5 | TRAIN: Last Loss: 2.30529\n",
            "Epoch 14 | Worker: 6 | TRAIN: Last Loss: 2.29759\n",
            "Epoch 14 | Worker: 7 | TRAIN: Last Loss: 2.29502\n",
            "Epoch 14 | Worker: 8 | TRAIN: Last Loss: 2.30849\n",
            "Epoch 14 | Worker: 9 | TRAIN: Last Loss: 2.30083\n",
            "Epoch 15 | Worker: 0 | TRAIN: Last Loss: 2.29449\n",
            "Epoch 15 | Worker: 1 | TRAIN: Last Loss: 2.30479\n",
            "Epoch 15 | Worker: 2 | TRAIN: Last Loss: 2.29584\n",
            "Epoch 15 | Worker: 3 | TRAIN: Last Loss: 2.29576\n",
            "Epoch 15 | Worker: 4 | TRAIN: Last Loss: 2.29016\n",
            "Epoch 15 | Worker: 5 | TRAIN: Last Loss: 2.30537\n",
            "Epoch 15 | Worker: 6 | TRAIN: Last Loss: 2.29728\n",
            "Epoch 15 | Worker: 7 | TRAIN: Last Loss: 2.29476\n",
            "Epoch 15 | Worker: 8 | TRAIN: Last Loss: 2.30820\n",
            "Epoch 15 | Worker: 9 | TRAIN: Last Loss: 2.30088\n",
            "Epoch 16 | Worker: 0 | TRAIN: Last Loss: 2.29425\n",
            "Epoch 16 | Worker: 1 | TRAIN: Last Loss: 2.30480\n",
            "Epoch 16 | Worker: 2 | TRAIN: Last Loss: 2.29562\n",
            "Epoch 16 | Worker: 3 | TRAIN: Last Loss: 2.29561\n",
            "Epoch 16 | Worker: 4 | TRAIN: Last Loss: 2.28971\n",
            "Epoch 16 | Worker: 5 | TRAIN: Last Loss: 2.30548\n",
            "Epoch 16 | Worker: 6 | TRAIN: Last Loss: 2.29702\n",
            "Epoch 16 | Worker: 7 | TRAIN: Last Loss: 2.29454\n",
            "Epoch 16 | Worker: 8 | TRAIN: Last Loss: 2.30794\n",
            "Epoch 16 | Worker: 9 | TRAIN: Last Loss: 2.30102\n",
            "Last Loss: 2.3034 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Epoch 17 | Worker: 0 | TRAIN: Last Loss: 2.29434\n",
            "Epoch 17 | Worker: 1 | TRAIN: Last Loss: 2.30524\n",
            "Epoch 17 | Worker: 2 | TRAIN: Last Loss: 2.29584\n",
            "Epoch 17 | Worker: 3 | TRAIN: Last Loss: 2.29533\n",
            "Epoch 17 | Worker: 4 | TRAIN: Last Loss: 2.29021\n",
            "Epoch 17 | Worker: 5 | TRAIN: Last Loss: 2.30524\n",
            "Epoch 17 | Worker: 6 | TRAIN: Last Loss: 2.29754\n",
            "Epoch 17 | Worker: 7 | TRAIN: Last Loss: 2.29521\n",
            "Epoch 17 | Worker: 8 | TRAIN: Last Loss: 2.30938\n",
            "Epoch 17 | Worker: 9 | TRAIN: Last Loss: 2.30049\n",
            "Epoch 18 | Worker: 0 | TRAIN: Last Loss: 2.29407\n",
            "Epoch 18 | Worker: 1 | TRAIN: Last Loss: 2.30515\n",
            "Epoch 18 | Worker: 2 | TRAIN: Last Loss: 2.29551\n",
            "Epoch 18 | Worker: 3 | TRAIN: Last Loss: 2.29530\n",
            "Epoch 18 | Worker: 4 | TRAIN: Last Loss: 2.28965\n",
            "Epoch 18 | Worker: 5 | TRAIN: Last Loss: 2.30525\n",
            "Epoch 18 | Worker: 6 | TRAIN: Last Loss: 2.29721\n",
            "Epoch 18 | Worker: 7 | TRAIN: Last Loss: 2.29460\n",
            "Epoch 18 | Worker: 8 | TRAIN: Last Loss: 2.30899\n",
            "Epoch 18 | Worker: 9 | TRAIN: Last Loss: 2.30051\n",
            "Epoch 19 | Worker: 0 | TRAIN: Last Loss: 2.29386\n",
            "Epoch 19 | Worker: 1 | TRAIN: Last Loss: 2.30511\n",
            "Epoch 19 | Worker: 2 | TRAIN: Last Loss: 2.29530\n",
            "Epoch 19 | Worker: 3 | TRAIN: Last Loss: 2.29522\n",
            "Epoch 19 | Worker: 4 | TRAIN: Last Loss: 2.28923\n",
            "Epoch 19 | Worker: 5 | TRAIN: Last Loss: 2.30533\n",
            "Epoch 19 | Worker: 6 | TRAIN: Last Loss: 2.29695\n",
            "Epoch 19 | Worker: 7 | TRAIN: Last Loss: 2.29438\n",
            "Epoch 19 | Worker: 8 | TRAIN: Last Loss: 2.30866\n",
            "Epoch 19 | Worker: 9 | TRAIN: Last Loss: 2.30055\n",
            "Epoch 20 | Worker: 0 | TRAIN: Last Loss: 2.29368\n",
            "Epoch 20 | Worker: 1 | TRAIN: Last Loss: 2.30509\n",
            "Epoch 20 | Worker: 2 | TRAIN: Last Loss: 2.29514\n",
            "Epoch 20 | Worker: 3 | TRAIN: Last Loss: 2.29511\n",
            "Epoch 20 | Worker: 4 | TRAIN: Last Loss: 2.28887\n",
            "Epoch 20 | Worker: 5 | TRAIN: Last Loss: 2.30544\n",
            "Epoch 20 | Worker: 6 | TRAIN: Last Loss: 2.29672\n",
            "Epoch 20 | Worker: 7 | TRAIN: Last Loss: 2.29420\n",
            "Epoch 20 | Worker: 8 | TRAIN: Last Loss: 2.30836\n",
            "Epoch 20 | Worker: 9 | TRAIN: Last Loss: 2.30068\n",
            "Last Loss: 2.3036 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Quantidade de workers maliciosos: 7\n",
            "Epoch 1 | Worker: 0 | TRAIN: Last Loss: 2.27664\n",
            "Epoch 1 | Worker: 1 | TRAIN: Last Loss: 2.22380\n",
            "Epoch 1 | Worker: 2 | TRAIN: Last Loss: 2.27291\n",
            "Epoch 1 | Worker: 3 | TRAIN: Last Loss: 2.28179\n",
            "Epoch 1 | Worker: 4 | TRAIN: Last Loss: 2.27621\n",
            "Epoch 1 | Worker: 5 | TRAIN: Last Loss: 2.22907\n",
            "Epoch 1 | Worker: 6 | TRAIN: Last Loss: 2.28008\n",
            "Epoch 1 | Worker: 7 | TRAIN: Last Loss: 2.25696\n",
            "Epoch 1 | Worker: 8 | TRAIN: Last Loss: 2.26188\n",
            "Epoch 1 | Worker: 9 | TRAIN: Last Loss: 2.26867\n",
            "Epoch 2 | Worker: 0 | TRAIN: Last Loss: 2.30006\n",
            "Epoch 2 | Worker: 1 | TRAIN: Last Loss: 2.30196\n",
            "Epoch 2 | Worker: 2 | TRAIN: Last Loss: 2.30165\n",
            "Epoch 2 | Worker: 3 | TRAIN: Last Loss: 2.30008\n",
            "Epoch 2 | Worker: 4 | TRAIN: Last Loss: 2.30044\n",
            "Epoch 2 | Worker: 5 | TRAIN: Last Loss: 2.30294\n",
            "Epoch 2 | Worker: 6 | TRAIN: Last Loss: 2.30129\n",
            "Epoch 2 | Worker: 7 | TRAIN: Last Loss: 2.15418\n",
            "Epoch 2 | Worker: 8 | TRAIN: Last Loss: 2.17604\n",
            "Epoch 2 | Worker: 9 | TRAIN: Last Loss: 2.19119\n",
            "Epoch 3 | Worker: 0 | TRAIN: Last Loss: 2.29905\n",
            "Epoch 3 | Worker: 1 | TRAIN: Last Loss: 2.30224\n",
            "Epoch 3 | Worker: 2 | TRAIN: Last Loss: 2.30188\n",
            "Epoch 3 | Worker: 3 | TRAIN: Last Loss: 2.29978\n",
            "Epoch 3 | Worker: 4 | TRAIN: Last Loss: 2.29909\n",
            "Epoch 3 | Worker: 5 | TRAIN: Last Loss: 2.30306\n",
            "Epoch 3 | Worker: 6 | TRAIN: Last Loss: 2.30013\n",
            "Epoch 3 | Worker: 7 | TRAIN: Last Loss: 1.65446\n",
            "Epoch 3 | Worker: 8 | TRAIN: Last Loss: 1.80724\n",
            "Epoch 3 | Worker: 9 | TRAIN: Last Loss: 1.82641\n",
            "Epoch 4 | Worker: 0 | TRAIN: Last Loss: 2.29838\n",
            "Epoch 4 | Worker: 1 | TRAIN: Last Loss: 2.30237\n",
            "Epoch 4 | Worker: 2 | TRAIN: Last Loss: 2.30149\n",
            "Epoch 4 | Worker: 3 | TRAIN: Last Loss: 2.29917\n",
            "Epoch 4 | Worker: 4 | TRAIN: Last Loss: 2.29784\n",
            "Epoch 4 | Worker: 5 | TRAIN: Last Loss: 2.30336\n",
            "Epoch 4 | Worker: 6 | TRAIN: Last Loss: 2.29962\n",
            "Epoch 4 | Worker: 7 | TRAIN: Last Loss: 0.77270\n",
            "Epoch 4 | Worker: 8 | TRAIN: Last Loss: 0.90637\n",
            "Epoch 4 | Worker: 9 | TRAIN: Last Loss: 0.88663\n",
            "Last Loss: 2.3340 | Accuracy: 10.10% | Correct: 1010/10000 | Precision: 0.9092 | Recall: 0.1010 | F1-score: 0.0185\n",
            "Epoch 5 | Worker: 0 | TRAIN: Last Loss: 2.29833\n",
            "Epoch 5 | Worker: 1 | TRAIN: Last Loss: 2.30410\n",
            "Epoch 5 | Worker: 2 | TRAIN: Last Loss: 2.30135\n",
            "Epoch 5 | Worker: 3 | TRAIN: Last Loss: 2.29924\n",
            "Epoch 5 | Worker: 4 | TRAIN: Last Loss: 2.29552\n",
            "Epoch 5 | Worker: 5 | TRAIN: Last Loss: 2.30445\n",
            "Epoch 5 | Worker: 6 | TRAIN: Last Loss: 2.29979\n",
            "Epoch 5 | Worker: 7 | TRAIN: Last Loss: 2.29871\n",
            "Epoch 5 | Worker: 8 | TRAIN: Last Loss: 2.30623\n",
            "Epoch 5 | Worker: 9 | TRAIN: Last Loss: 2.30293\n",
            "Epoch 6 | Worker: 0 | TRAIN: Last Loss: 2.29738\n",
            "Epoch 6 | Worker: 1 | TRAIN: Last Loss: 2.30361\n",
            "Epoch 6 | Worker: 2 | TRAIN: Last Loss: 2.30089\n",
            "Epoch 6 | Worker: 3 | TRAIN: Last Loss: 2.29878\n",
            "Epoch 6 | Worker: 4 | TRAIN: Last Loss: 2.29450\n",
            "Epoch 6 | Worker: 5 | TRAIN: Last Loss: 2.30463\n",
            "Epoch 6 | Worker: 6 | TRAIN: Last Loss: 2.29916\n",
            "Epoch 6 | Worker: 7 | TRAIN: Last Loss: 2.29805\n",
            "Epoch 6 | Worker: 8 | TRAIN: Last Loss: 2.30615\n",
            "Epoch 6 | Worker: 9 | TRAIN: Last Loss: 2.30297\n",
            "Epoch 7 | Worker: 0 | TRAIN: Last Loss: 2.29686\n",
            "Epoch 7 | Worker: 1 | TRAIN: Last Loss: 2.30357\n",
            "Epoch 7 | Worker: 2 | TRAIN: Last Loss: 2.30052\n",
            "Epoch 7 | Worker: 3 | TRAIN: Last Loss: 2.29832\n",
            "Epoch 7 | Worker: 4 | TRAIN: Last Loss: 2.29368\n",
            "Epoch 7 | Worker: 5 | TRAIN: Last Loss: 2.30481\n",
            "Epoch 7 | Worker: 6 | TRAIN: Last Loss: 2.29875\n",
            "Epoch 7 | Worker: 7 | TRAIN: Last Loss: 2.29746\n",
            "Epoch 7 | Worker: 8 | TRAIN: Last Loss: 2.30607\n",
            "Epoch 7 | Worker: 9 | TRAIN: Last Loss: 2.30290\n",
            "Epoch 8 | Worker: 0 | TRAIN: Last Loss: 2.29641\n",
            "Epoch 8 | Worker: 1 | TRAIN: Last Loss: 2.30360\n",
            "Epoch 8 | Worker: 2 | TRAIN: Last Loss: 2.30020\n",
            "Epoch 8 | Worker: 3 | TRAIN: Last Loss: 2.29788\n",
            "Epoch 8 | Worker: 4 | TRAIN: Last Loss: 2.29296\n",
            "Epoch 8 | Worker: 5 | TRAIN: Last Loss: 2.30498\n",
            "Epoch 8 | Worker: 6 | TRAIN: Last Loss: 2.29839\n",
            "Epoch 8 | Worker: 7 | TRAIN: Last Loss: 2.29694\n",
            "Epoch 8 | Worker: 8 | TRAIN: Last Loss: 2.30601\n",
            "Epoch 8 | Worker: 9 | TRAIN: Last Loss: 2.30280\n",
            "Last Loss: 2.3034 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Epoch 9 | Worker: 0 | TRAIN: Last Loss: 2.29610\n",
            "Epoch 9 | Worker: 1 | TRAIN: Last Loss: 2.30412\n",
            "Epoch 9 | Worker: 2 | TRAIN: Last Loss: 2.29993\n",
            "Epoch 9 | Worker: 3 | TRAIN: Last Loss: 2.29760\n",
            "Epoch 9 | Worker: 4 | TRAIN: Last Loss: 2.29270\n",
            "Epoch 9 | Worker: 5 | TRAIN: Last Loss: 2.30464\n",
            "Epoch 9 | Worker: 6 | TRAIN: Last Loss: 2.29846\n",
            "Epoch 9 | Worker: 7 | TRAIN: Last Loss: 2.29743\n",
            "Epoch 9 | Worker: 8 | TRAIN: Last Loss: 2.30755\n",
            "Epoch 9 | Worker: 9 | TRAIN: Last Loss: 2.30210\n",
            "Epoch 10 | Worker: 0 | TRAIN: Last Loss: 2.29573\n",
            "Epoch 10 | Worker: 1 | TRAIN: Last Loss: 2.30411\n",
            "Epoch 10 | Worker: 2 | TRAIN: Last Loss: 2.29968\n",
            "Epoch 10 | Worker: 3 | TRAIN: Last Loss: 2.29725\n",
            "Epoch 10 | Worker: 4 | TRAIN: Last Loss: 2.29207\n",
            "Epoch 10 | Worker: 5 | TRAIN: Last Loss: 2.30483\n",
            "Epoch 10 | Worker: 6 | TRAIN: Last Loss: 2.29814\n",
            "Epoch 10 | Worker: 7 | TRAIN: Last Loss: 2.29691\n",
            "Epoch 10 | Worker: 8 | TRAIN: Last Loss: 2.30735\n",
            "Epoch 10 | Worker: 9 | TRAIN: Last Loss: 2.30207\n",
            "Epoch 11 | Worker: 0 | TRAIN: Last Loss: 2.29540\n",
            "Epoch 11 | Worker: 1 | TRAIN: Last Loss: 2.30411\n",
            "Epoch 11 | Worker: 2 | TRAIN: Last Loss: 2.29945\n",
            "Epoch 11 | Worker: 3 | TRAIN: Last Loss: 2.29693\n",
            "Epoch 11 | Worker: 4 | TRAIN: Last Loss: 2.29152\n",
            "Epoch 11 | Worker: 5 | TRAIN: Last Loss: 2.30501\n",
            "Epoch 11 | Worker: 6 | TRAIN: Last Loss: 2.29785\n",
            "Epoch 11 | Worker: 7 | TRAIN: Last Loss: 2.29646\n",
            "Epoch 11 | Worker: 8 | TRAIN: Last Loss: 2.30717\n",
            "Epoch 11 | Worker: 9 | TRAIN: Last Loss: 2.30207\n",
            "Epoch 12 | Worker: 0 | TRAIN: Last Loss: 2.29510\n",
            "Epoch 12 | Worker: 1 | TRAIN: Last Loss: 2.30412\n",
            "Epoch 12 | Worker: 2 | TRAIN: Last Loss: 2.29924\n",
            "Epoch 12 | Worker: 3 | TRAIN: Last Loss: 2.29664\n",
            "Epoch 12 | Worker: 4 | TRAIN: Last Loss: 2.29101\n",
            "Epoch 12 | Worker: 5 | TRAIN: Last Loss: 2.30517\n",
            "Epoch 12 | Worker: 6 | TRAIN: Last Loss: 2.29759\n",
            "Epoch 12 | Worker: 7 | TRAIN: Last Loss: 2.29606\n",
            "Epoch 12 | Worker: 8 | TRAIN: Last Loss: 2.30701\n",
            "Epoch 12 | Worker: 9 | TRAIN: Last Loss: 2.30205\n",
            "Last Loss: 2.3036 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Epoch 13 | Worker: 0 | TRAIN: Last Loss: 2.29491\n",
            "Epoch 13 | Worker: 1 | TRAIN: Last Loss: 2.30459\n",
            "Epoch 13 | Worker: 2 | TRAIN: Last Loss: 2.29906\n",
            "Epoch 13 | Worker: 3 | TRAIN: Last Loss: 2.29649\n",
            "Epoch 13 | Worker: 4 | TRAIN: Last Loss: 2.29097\n",
            "Epoch 13 | Worker: 5 | TRAIN: Last Loss: 2.30482\n",
            "Epoch 13 | Worker: 6 | TRAIN: Last Loss: 2.29774\n",
            "Epoch 13 | Worker: 7 | TRAIN: Last Loss: 2.29664\n",
            "Epoch 13 | Worker: 8 | TRAIN: Last Loss: 2.30848\n",
            "Epoch 13 | Worker: 9 | TRAIN: Last Loss: 2.30155\n",
            "Epoch 14 | Worker: 0 | TRAIN: Last Loss: 2.29466\n",
            "Epoch 14 | Worker: 1 | TRAIN: Last Loss: 2.30455\n",
            "Epoch 14 | Worker: 2 | TRAIN: Last Loss: 2.29890\n",
            "Epoch 14 | Worker: 3 | TRAIN: Last Loss: 2.29625\n",
            "Epoch 14 | Worker: 4 | TRAIN: Last Loss: 2.29049\n",
            "Epoch 14 | Worker: 5 | TRAIN: Last Loss: 2.30500\n",
            "Epoch 14 | Worker: 6 | TRAIN: Last Loss: 2.29749\n",
            "Epoch 14 | Worker: 7 | TRAIN: Last Loss: 2.29621\n",
            "Epoch 14 | Worker: 8 | TRAIN: Last Loss: 2.30820\n",
            "Epoch 14 | Worker: 9 | TRAIN: Last Loss: 2.30152\n",
            "Epoch 15 | Worker: 0 | TRAIN: Last Loss: 2.29444\n",
            "Epoch 15 | Worker: 1 | TRAIN: Last Loss: 2.30452\n",
            "Epoch 15 | Worker: 2 | TRAIN: Last Loss: 2.29874\n",
            "Epoch 15 | Worker: 3 | TRAIN: Last Loss: 2.29604\n",
            "Epoch 15 | Worker: 4 | TRAIN: Last Loss: 2.29008\n",
            "Epoch 15 | Worker: 5 | TRAIN: Last Loss: 2.30517\n",
            "Epoch 15 | Worker: 6 | TRAIN: Last Loss: 2.29728\n",
            "Epoch 15 | Worker: 7 | TRAIN: Last Loss: 2.29585\n",
            "Epoch 15 | Worker: 8 | TRAIN: Last Loss: 2.30795\n",
            "Epoch 15 | Worker: 9 | TRAIN: Last Loss: 2.30156\n",
            "Epoch 16 | Worker: 0 | TRAIN: Last Loss: 2.29423\n",
            "Epoch 16 | Worker: 1 | TRAIN: Last Loss: 2.30450\n",
            "Epoch 16 | Worker: 2 | TRAIN: Last Loss: 2.29861\n",
            "Epoch 16 | Worker: 3 | TRAIN: Last Loss: 2.29584\n",
            "Epoch 16 | Worker: 4 | TRAIN: Last Loss: 2.28971\n",
            "Epoch 16 | Worker: 5 | TRAIN: Last Loss: 2.30532\n",
            "Epoch 16 | Worker: 6 | TRAIN: Last Loss: 2.29708\n",
            "Epoch 16 | Worker: 7 | TRAIN: Last Loss: 2.29552\n",
            "Epoch 16 | Worker: 8 | TRAIN: Last Loss: 2.30772\n",
            "Epoch 16 | Worker: 9 | TRAIN: Last Loss: 2.30161\n",
            "Last Loss: 2.3038 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n",
            "Epoch 17 | Worker: 0 | TRAIN: Last Loss: 2.29412\n",
            "Epoch 17 | Worker: 1 | TRAIN: Last Loss: 2.30493\n",
            "Epoch 17 | Worker: 2 | TRAIN: Last Loss: 2.29848\n",
            "Epoch 17 | Worker: 3 | TRAIN: Last Loss: 2.29577\n",
            "Epoch 17 | Worker: 4 | TRAIN: Last Loss: 2.28978\n",
            "Epoch 17 | Worker: 5 | TRAIN: Last Loss: 2.30496\n",
            "Epoch 17 | Worker: 6 | TRAIN: Last Loss: 2.29728\n",
            "Epoch 17 | Worker: 7 | TRAIN: Last Loss: 2.29616\n",
            "Epoch 17 | Worker: 8 | TRAIN: Last Loss: 2.30913\n",
            "Epoch 17 | Worker: 9 | TRAIN: Last Loss: 2.30120\n",
            "Epoch 18 | Worker: 0 | TRAIN: Last Loss: 2.29394\n",
            "Epoch 18 | Worker: 1 | TRAIN: Last Loss: 2.30486\n",
            "Epoch 18 | Worker: 2 | TRAIN: Last Loss: 2.29837\n",
            "Epoch 18 | Worker: 3 | TRAIN: Last Loss: 2.29560\n",
            "Epoch 18 | Worker: 4 | TRAIN: Last Loss: 2.28942\n",
            "Epoch 18 | Worker: 5 | TRAIN: Last Loss: 2.30513\n",
            "Epoch 18 | Worker: 6 | TRAIN: Last Loss: 2.29708\n",
            "Epoch 18 | Worker: 7 | TRAIN: Last Loss: 2.29580\n",
            "Epoch 18 | Worker: 8 | TRAIN: Last Loss: 2.30879\n",
            "Epoch 18 | Worker: 9 | TRAIN: Last Loss: 2.30121\n",
            "Epoch 19 | Worker: 0 | TRAIN: Last Loss: 2.29378\n",
            "Epoch 19 | Worker: 1 | TRAIN: Last Loss: 2.30481\n",
            "Epoch 19 | Worker: 2 | TRAIN: Last Loss: 2.29827\n",
            "Epoch 19 | Worker: 3 | TRAIN: Last Loss: 2.29545\n",
            "Epoch 19 | Worker: 4 | TRAIN: Last Loss: 2.28911\n",
            "Epoch 19 | Worker: 5 | TRAIN: Last Loss: 2.30528\n",
            "Epoch 19 | Worker: 6 | TRAIN: Last Loss: 2.29690\n",
            "Epoch 19 | Worker: 7 | TRAIN: Last Loss: 2.29548\n",
            "Epoch 19 | Worker: 8 | TRAIN: Last Loss: 2.30848\n",
            "Epoch 19 | Worker: 9 | TRAIN: Last Loss: 2.30126\n",
            "Epoch 20 | Worker: 0 | TRAIN: Last Loss: 2.29364\n",
            "Epoch 20 | Worker: 1 | TRAIN: Last Loss: 2.30476\n",
            "Epoch 20 | Worker: 2 | TRAIN: Last Loss: 2.29818\n",
            "Epoch 20 | Worker: 3 | TRAIN: Last Loss: 2.29532\n",
            "Epoch 20 | Worker: 4 | TRAIN: Last Loss: 2.28883\n",
            "Epoch 20 | Worker: 5 | TRAIN: Last Loss: 2.30543\n",
            "Epoch 20 | Worker: 6 | TRAIN: Last Loss: 2.29674\n",
            "Epoch 20 | Worker: 7 | TRAIN: Last Loss: 2.29519\n",
            "Epoch 20 | Worker: 8 | TRAIN: Last Loss: 2.30820\n",
            "Epoch 20 | Worker: 9 | TRAIN: Last Loss: 2.30133\n",
            "Last Loss: 2.3039 | Accuracy: 11.35% | Correct: 1135/10000 | Precision: 0.8994 | Recall: 0.1135 | F1-score: 0.0231\n"
          ]
        }
      ],
      "source": [
        "def simular(wm):\n",
        "    model = []              # armazenará instacias de modelos de neural networks\n",
        "    optimizer = []          # armazenará optimizadores para cada instancia de modelo\n",
        "    loss_fn = []            # armazena as funções de perda para cada instancia de modelo\n",
        "\n",
        "    workers_maliciosos = []\n",
        "    for i in range(0, wm):\n",
        "        workers_maliciosos.append(i)\n",
        "\n",
        "    for i in range(0, args.n_workers):\n",
        "        model.append(Net().to(device))\n",
        "        optimizer.append(optim.SGD(model[i].parameters(), lr=args.learning_rate))\n",
        "        loss_fn.append(F.nll_loss)\n",
        "\n",
        "    #cria args.n_workers trainloaders e um testloader geral para testar o modelo global\n",
        "    trainloaders, testloader = prepare_dataset()\n",
        "\n",
        "    global_model = Net().to(device)\n",
        "\n",
        "    for i in range(1, args.epochs+1):\n",
        "        #treina o modelo local de cada worker\n",
        "        train(args, model, device, trainloaders, optimizer, loss_fn, i)\n",
        "\n",
        "        if wm>1:\n",
        "            ataque(args, global_model, model, workers_maliciosos)\n",
        "\n",
        "        if i % 4 == 0:\n",
        "            #agrega os modelos locais no modelo global\n",
        "            #os modelos locais são atualizados para o modelo global\n",
        "            fedavg_aggregation(model, global_model)\n",
        "\n",
        "            #testa o modelo global\n",
        "            test(global_model, device, testloader)\n",
        "\n",
        "for wm in [1, 2, 3, 4, 5, 6, 7]:          # cada número na lista representa a quantidade de atacantes maliciosos e cada iteração do for é uma simulação\n",
        "  print(f\"Quantidade de workers maliciosos: {wm}\")\n",
        "  with open(f\"teste{wm}.txt\", 'w') as file:\n",
        "    file.write(f\"Quantidade de workers maliciosos: {wm}\\n\")\n",
        "  simular(wm)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNz8gk16gvpq493cu37C1nx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}