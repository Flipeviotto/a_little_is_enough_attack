{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Flipeviotto/a_little_is_enough_attack/blob/Version-3/Ataque_LIE_artigo_VERSAO_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiOoUBLzfz59"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor, Normalize, Compose\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import random\n",
        "\n",
        "maior = 0\n",
        "soma_acuracia = 0\n",
        "\n",
        "# Classe Arguments para encapsular hiperparâmetros\n",
        "class Arguments:\n",
        "    def __init__(self):\n",
        "        self.train_batch_size = 83  # Conforme o artigo\n",
        "        self.test_batch_size = 83 # Tamanho do lote de teste maior para avaliação mais eficiente\n",
        "        self.epochs = 150\n",
        "        self.learning_rate = 0.1\n",
        "        self.momentum = 0.9\n",
        "        self.weight_decay = 1e-4\n",
        "        self.n_workers = 51\n",
        "        self.n_corrupted_workers = 12 # 24% dos trabalhadores são corrompidos (12/51)\n",
        "        self.no_cuda = False\n",
        "\n",
        "args = Arguments()\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "# Definindo a rede neural (corrigido: fc1 e fc2 renomeados para hidden_layer e output_layer)\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.hidden_layer = nn.Linear(784, 100)  # 784 features de entrada, 100 neurônios ocultos\n",
        "        self.output_layer = nn.Linear(100, 10)   # 100 neurônios ocultos, 10 classes de saída\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)  # Achatar a entrada\n",
        "        x = F.relu(self.hidden_layer(x))  # Aplicar ReLU na camada oculta\n",
        "        x = self.output_layer(x)          # Camada de saída (sem softmax aqui, aplicado na função de perda)\n",
        "        x = F.softmax(x, dim=1)           # usa softmax aqui para\n",
        "        return x\n",
        "\n",
        "# Função para preparar datasets divididos para os trabalhadores (sem mudanças necessárias)\n",
        "def prepare_dataset():\n",
        "    transform = Compose([\n",
        "        ToTensor(),\n",
        "        Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "    test_dataset = MNIST(root='./data', train=False, transform=transform)\n",
        "\n",
        "    trainloaders = []\n",
        "    subset_size = len(train_dataset) // args.n_workers\n",
        "    for i in range(args.n_workers):\n",
        "        worker_subset = Subset(train_dataset, range(i * subset_size, (i + 1) * subset_size))\n",
        "        trainloader = DataLoader(worker_subset, batch_size=args.train_batch_size, shuffle=True)\n",
        "        trainloaders.append(trainloader)\n",
        "\n",
        "    testloader = DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False) # Lote maior para teste\n",
        "\n",
        "    return trainloaders, testloader\n",
        "\n",
        "# Função de treinamento local para cada trabalhador\n",
        "def train(args: Arguments, models: list, device, train_loaders, optimizers, loss_fns, epoch):\n",
        "    loss = [0] * args.n_workers\n",
        "\n",
        "    for j in range(args.n_workers):\n",
        "        models[j].train()\n",
        "        for data, target in train_loaders[j]:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizers[j].zero_grad()\n",
        "            output = models[j](data)\n",
        "            loss[j] = loss_fns[j](output, target)\n",
        "\n",
        "            loss[j].backward()\n",
        "\n",
        "            # Clipping para evitar explosão de gradientes\n",
        "            torch.nn.utils.clip_grad_norm_(models[j].parameters(), max_norm=1.0)\n",
        "            optimizers[j].step()\n",
        "\n",
        "# Função de agregação FedAvg\n",
        "def fedavg_aggregation(models: list, global_model):\n",
        "    all_params = [list(model.parameters()) for model in models]\n",
        "    average_params = [torch.stack(params).mean(0) for params in zip(*all_params)]\n",
        "\n",
        "    for global_param, avg_param in zip(global_model.parameters(), average_params):\n",
        "        global_param.data.copy_(avg_param)\n",
        "\n",
        "    # Atualiza os modelos locais com os pesos do modelo global\n",
        "    for model in models:\n",
        "        model.load_state_dict(global_model.state_dict())\n",
        "\n",
        "# Função de teste para o modelo global\n",
        "def test(global_model, device, test_loader, epoch):\n",
        "    global maior\n",
        "    global soma_acuracia\n",
        "    global_model.eval()\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = global_model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            all_predictions.extend(pred.cpu().numpy().flatten())\n",
        "            all_targets.extend(target.cpu().numpy().flatten())\n",
        "\n",
        "    total_samples = len(test_loader.dataset)\n",
        "    precision, recall, f1_score, _ = precision_recall_fscore_support(all_targets, all_predictions, average='weighted', zero_division=1)\n",
        "    accuracy = (correct / total_samples) * 100\n",
        "    soma_acuracia = soma_acuracia + accuracy\n",
        "    if(accuracy>maior):\n",
        "      maior = accuracy\n",
        "      print(f\"Maior acurácia: {maior}\")\n",
        "    with open(f\"teste{wm}.txt\", 'a') as file:\n",
        "      file.write(f'epoca {epoch} | Accuracy: {accuracy:.2f}% | Correct: {correct}/{total_samples} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1-score: {f1_score:.4f}\\n')\n",
        "    #print(f'Teste: Precisão: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1_score:.4f}, Acurácia: {accuracy:.2f}%')\n",
        "\n",
        "\n",
        "from scipy.stats import norm\n",
        "\n",
        "def ataque(args:Arguments, model:list, workers_maliciosos:list):\n",
        "    total_clientes = args.n_workers\n",
        "\n",
        "    #calcular a taxa de perturbação\n",
        "    #s = total_clientes/2 + 1 - len(workers_maliciosos)\n",
        "    #possibilidade = (total_clientes-s)/total_clientes\n",
        "    #z = norm.ppf(1 - s / args.n_workers)\n",
        "\n",
        "    #s = (args.n_workers // 2 + 1) - args.n_corrupted_workers\n",
        "    #z = norm.ppf(1 - s / args.n_workers)\n",
        "\n",
        "    z = 1.5\n",
        "\n",
        "    # somar parametros\n",
        "    soma_parametros = MLP().to(device)\n",
        "    media = MLP().to(device)\n",
        "    desvio_padrao = MLP().to(device)\n",
        "    desvio_padrao_aux = MLP().to(device)\n",
        "\n",
        "    # inicializa programas com zero\n",
        "    for parametro, parametro_media, desvio, desvio_pad in zip(soma_parametros.parameters(), media.parameters(), desvio_padrao_aux.parameters(), desvio_padrao.parameters()):\n",
        "        desvio_pad.data.zero_()\n",
        "        parametro.data.zero_()\n",
        "        parametro_media.data.zero_()\n",
        "        desvio.data.zero_()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for malicioso in workers_maliciosos:\n",
        "        for modelo_param, soma_param in zip(model[malicioso].parameters(), soma_parametros.parameters()):\n",
        "          soma_param.data += modelo_param.data\n",
        "\n",
        "      #calcular media\n",
        "      for soma_param, parametro_media in zip(soma_parametros.parameters(), media.parameters()):\n",
        "        parametro_media.data = soma_param.data/len(workers_maliciosos)\n",
        "\n",
        "      # calculo desvio padrao\n",
        "      for malicioso in workers_maliciosos:\n",
        "        for parametro_modelo, variancia, parametro_media in zip(model[malicioso].parameters(), desvio_padrao_aux.parameters(), media.parameters()):\n",
        "            diff_squared = (parametro_modelo.data - parametro_media.data) ** 2\n",
        "            variancia.data += diff_squared  # Acumula diferença ao quadrado\n",
        "\n",
        "      for variancia, desvio in zip(desvio_padrao_aux.parameters(), desvio_padrao.parameters()):\n",
        "        desvio.data = torch.sqrt(variancia.data / len(workers_maliciosos))\n",
        "\n",
        "      # alterar parametros\n",
        "      for malicioso in workers_maliciosos:\n",
        "        for parametro, desvio, parametro_media in zip(model[malicioso].parameters(), desvio_padrao.parameters(), media.parameters()):\n",
        "          parametro.data = parametro_media.data + z * desvio.data\n",
        "\n",
        "    return 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Função principal\n",
        "def main(wm):\n",
        "    models = [MLP().to(device) for _ in range(args.n_workers)]\n",
        "    optimizers = [optim.SGD(model.parameters(), lr=args.learning_rate, momentum=args.momentum, weight_decay=args.weight_decay) for model in models]\n",
        "    loss_fns = [F.cross_entropy for _ in range(args.n_workers)]\n",
        "\n",
        "    workers_maliciosos = []\n",
        "    #workers_maliciosos = random.sample(range(args.n_workers), args.n_corrupted_workers)\n",
        "    for i in range(0,wm):\n",
        "       workers_maliciosos.append(i)\n",
        "\n",
        "    # Criando os loaders de dados para cada trabalhador e o loader de teste global\n",
        "    trainloaders, testloader = prepare_dataset()\n",
        "    global_model = MLP().to(device)\n",
        "\n",
        "    # Loop de treinamento federado\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        train(args, models, device, trainloaders, optimizers, loss_fns, epoch)\n",
        "\n",
        "\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "            if wm>1:\n",
        "                ataque(args, models, workers_maliciosos)\n",
        "            fedavg_aggregation(models, global_model)\n",
        "            test(global_model, device, testloader, epoch)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  for wm in [args.n_workers]:                  # passo com as quantidades de workers maliciosos em cada simulação\n",
        "    print(f\"Quantidade de workers maliciosos: {wm}\")\n",
        "    with open(f\"teste{wm}.txt\", 'w') as file:\n",
        "      file.write(f\"Quantidade de workers maliciosos: {wm}\\n\")\n",
        "    main(wm)\n",
        "    print(f\"media_acuracia: {soma_acuracia/150}\")\n",
        "    print(f\"Maior acurácia: {maior}\")\n",
        "    with open(f\"teste51.txt\", 'a') as file:\n",
        "      file.write(f\"Maior acurácia: {maior}\\n\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObru/Nk6ygL0XCgJPR1qb2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}