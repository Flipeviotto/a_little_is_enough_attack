{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Flipeviotto/a_little_is_enough_attack/blob/main/Ataque_LIE_Version5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor, Normalize, Compose\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "metadata": {
        "id": "bV-Gf8atM6gs"
      },
      "execution_count": 366,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maior = 0\n",
        "\n",
        "\n",
        "# Classe Arguments para encapsular hiperparâmetros\n",
        "class Arguments:\n",
        "    def __init__(self):\n",
        "        self.train_batch_size = 83\n",
        "        self.test_batch_size = 83\n",
        "        self.epochs = 150\n",
        "        self.lr = 0.1                 # taxa de aprendizado, controla o tamanho da atualização dos parametros\n",
        "        self.momentum = 0.9           # cria um termo de velocidade que influencia a atualização dos parametros\n",
        "        self.l2 = 1e-4                # parametro de decaimento de peso, penalisa pesos muito grantes no treinamento\n",
        "        self.n_workers = 51           # quantidade de dispositivos na simulação\n",
        "        self.n_corrupted_workers = 12 # quantidade de dispositivos maliciosos\n",
        "        self.no_cuda = False\n",
        "\n",
        "args = Arguments()\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ],
      "metadata": {
        "id": "Hm7j4sx1NAdn"
      },
      "execution_count": 367,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A rede"
      ],
      "metadata": {
        "id": "HSs7NTTwXBKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(MLP, self).__init__()\n",
        "      self._f1 = torch.nn.Linear(28 * 28, 100)\n",
        "      self._f2 = torch.nn.Linear(100, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = torch.nn.functional.relu(self._f1(x.view(-1, 28 * 28)))\n",
        "      x = torch.nn.functional.log_softmax(self._f2(x), dim=1)\n",
        "      return x"
      ],
      "metadata": {
        "id": "pVBTNn5gNDz0"
      },
      "execution_count": 368,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preparar dados"
      ],
      "metadata": {
        "id": "rx3hwlCdN7VP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getdata():\n",
        "    return MNIST(root=\"./data\", train=True, download=True, transform=ToTensor()), MNIST(root=\"./data\", train=False, download=True, transform=ToTensor())\n",
        "\n",
        "def prepare_mnist_dataset():\n",
        "    train_dataset, test_dataset = getdata()  # Obtém os datasets de treinamento e teste\n",
        "\n",
        "    # Divisão do dataset de treinamento em partes para cada worker\n",
        "    train_sets = []\n",
        "    parte_size = len(train_dataset) // args.n_workers\n",
        "\n",
        "    for i in range(args.n_workers):\n",
        "        inicio = i * parte_size\n",
        "        fim = (i + 1) * parte_size\n",
        "        parte = Subset(train_dataset, range(inicio, fim))\n",
        "        train_sets.append(parte)\n",
        "\n",
        "    # Lidando com sobras de dados\n",
        "    if len(train_dataset) % args.n_workers != 0:\n",
        "        sobras = Subset(train_dataset, range(args.n_workers * parte_size, len(train_dataset)))\n",
        "        train_sets.append(sobras)\n",
        "\n",
        "    # Criação dos DataLoaders\n",
        "    trainloaders = []\n",
        "    for train_set in train_sets:\n",
        "        trainloaders.append(DataLoader(train_set, batch_size=args.train_batch_size, shuffle=True))\n",
        "\n",
        "    testloader = DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False)\n",
        "\n",
        "    return trainloaders, testloader"
      ],
      "metadata": {
        "id": "rd0wVJf6NH7_"
      },
      "execution_count": 369,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# treino"
      ],
      "metadata": {
        "id": "jq5bzDxh6sRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(args: Arguments, models: list, device, train_loaders, optimizers, criterion, epoch):\n",
        "\n",
        "    for j in range(args.n_workers):\n",
        "        models[j].train()\n",
        "        for data, target in train_loaders[j]:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = models[j](data)\n",
        "            loss = criterion(output, target)\n",
        "            optimizers[j].zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            # Clipping para evitar explosão de gradientes\n",
        "            torch.nn.utils.clip_grad_norm_(models[j].parameters(), max_norm=1.0)\n",
        "            optimizers[j].step()"
      ],
      "metadata": {
        "id": "F6dgQ0sSNL1x"
      },
      "execution_count": 370,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# agregação"
      ],
      "metadata": {
        "id": "IlW8UcQ36ox0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fedavg_aggregation(models: list, global_model):\n",
        "    all_params = [list(model.parameters()) for model in models]\n",
        "    average_params = [torch.stack(params).mean(0) for params in zip(*all_params)]\n",
        "\n",
        "    for global_param, avg_param in zip(global_model.parameters(), average_params):\n",
        "        global_param.data.copy_(avg_param)\n",
        "\n",
        "    # Atualiza os modelos locais com os pesos do modelo global\n",
        "    for model in models:\n",
        "        model.load_state_dict(global_model.state_dict())"
      ],
      "metadata": {
        "id": "7vzJSVqnNQ3P"
      },
      "execution_count": 371,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# teste"
      ],
      "metadata": {
        "id": "tvzPxDCx6mM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(global_model, device, test_loader, epoch):\n",
        "    global maior\n",
        "\n",
        "    global_model.eval()\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = global_model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            all_predictions.extend(pred.cpu().numpy().flatten())\n",
        "            all_targets.extend(target.cpu().numpy().flatten())\n",
        "\n",
        "    total_samples = len(test_loader.dataset)\n",
        "    precision, recall, f1_score, _ = precision_recall_fscore_support(all_targets, all_predictions, average='weighted', zero_division=1)\n",
        "    accuracy = (correct / total_samples) * 100\n",
        "    #if(accuracy>maior):\n",
        "      #maior = accuracy\n",
        "      #print(f\"Maior acurácia: {maior}\")\n",
        "    with open(f\"teste{wm}.txt\", 'a') as file:\n",
        "      file.write(f'epoca {epoch} | Accuracy: {accuracy:.2f}% | Correct: {correct}/{total_samples} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1-score: {f1_score:.4f}\\n')\n",
        "    print(f'Teste: Precisão: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1_score:.4f}, Acurácia: {accuracy:.2f}%')\n"
      ],
      "metadata": {
        "id": "KKZcgsv_NUUF"
      },
      "execution_count": 372,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ataque \"a little is enough\"\n",
        "\n",
        "Ainda em construção"
      ],
      "metadata": {
        "id": "2Tr-mHXi6w9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import norm\n",
        "\n",
        "def ataque(args:Arguments, model:list, workers_maliciosos:list):\n",
        "  \"\"\"\n",
        "    Altera os parametros dos workers maliciosos.\n",
        "\n",
        "    input\n",
        "    args: contem informações sobre o modelo\n",
        "    model: lista de modelos\n",
        "    workers_maliciosos: lista de indices dos workers maliciosos\n",
        "\n",
        "    output\n",
        "    nenhum\n",
        "  \"\"\"\n",
        "\n",
        "  p = 0\n",
        "\n",
        "  #calcular a taxa de perturbação\n",
        "  s = args.n_workers/2 + 1 - len(workers_maliciosos)\n",
        "  possibilidade = (args.n_workers-s)/args.n_workers\n",
        "  z = norm.ppf(possibilidade)\n",
        "  #print(f\"taxa de perturbação real: {z}\")\n",
        "\n",
        "\n",
        "\n",
        "  # instancia modelos auxiliares\n",
        "  soma_parametros = MLP().to(device)\n",
        "  media = MLP().to(device)\n",
        "  desvio_padrao = MLP().to(device)\n",
        "  desvio_padrao_aux = MLP().to(device)\n",
        "\n",
        "\n",
        "  #print(\"soma inicio: \")\n",
        "  #for param in soma_parametros.parameters():\n",
        "  #  print(param)\n",
        "  #  break;\n",
        "\n",
        "\n",
        "  # inicializa modelos com zero\n",
        "  for soma, param_media, desvio_aux, desvio_pad in zip(soma_parametros.parameters(), media.parameters(), desvio_padrao_aux.parameters(), desvio_padrao.parameters()):\n",
        "    soma.data.zero_()\n",
        "    desvio_aux.data.zero_()\n",
        "\n",
        "\n",
        "  #print(\"soma zerada:\")    # para saber se esta zerando\n",
        "  #for param in soma_parametros.parameters():\n",
        "  #  print(param)\n",
        "  #  break;\n",
        "\n",
        "\n",
        "  # somar parametros\n",
        "  with torch.no_grad():\n",
        "    for malicioso in workers_maliciosos:\n",
        "      #print(f\"Pesos do modelo para o worker {malicioso}:\")\n",
        "      #for name, param in model[malicioso].named_parameters():\n",
        "      #  print(f\"{name}: {param.data}\")\n",
        "      #  break\n",
        "      #print(\"\\n\")\n",
        "\n",
        "\n",
        "      for modelo_param, soma_param in zip(model[malicioso].parameters(), soma_parametros.parameters()):\n",
        "        soma_param.data += modelo_param.data\n",
        "\n",
        "\n",
        "    #print(\"soma final: \")\n",
        "    #for param in soma_parametros.parameters():\n",
        "    #  print(param)\n",
        "    #  break;\n",
        "\n",
        "\n",
        "    #calcular media\n",
        "    for soma_param, parametro_media in zip(soma_parametros.parameters(), media.parameters()):\n",
        "      parametro_media.data = soma_param.data/len(workers_maliciosos)\n",
        "      #if p == 0:\n",
        "      #  print(\"media: \")\n",
        "      #  print(parametro_media.data)\n",
        "      #  p = 1\n",
        "    #p=0\n",
        "\n",
        "    # calculo desvio padrao\n",
        "    for malicioso in workers_maliciosos:\n",
        "      #p=0\n",
        "      for parametro_modelo, variancia, parametro_media in zip(model[malicioso].parameters(), desvio_padrao_aux.parameters(), media.parameters()):\n",
        "        variancia.data += ((parametro_modelo.data - parametro_media.data) ** 2)\n",
        "        #if p==0:\n",
        "        #  print(\"worker: \")\n",
        "        #  print(parametro_modelo.data)\n",
        "        #  p=1\n",
        "\n",
        "    for variancia, desvio in zip(desvio_padrao_aux.parameters(), desvio_padrao.parameters()):\n",
        "      desvio.data = torch.sqrt(variancia.data / len(workers_maliciosos))\n",
        "\n",
        "    # alterar parametros\n",
        "    for malicioso in workers_maliciosos:\n",
        "      for parametro, desvio, parametro_media in zip(model[malicioso].parameters(), desvio_padrao.parameters(), media.parameters()):\n",
        "        parametro.data = parametro_media.data + z * desvio.data\n",
        "        #if(p==1):\n",
        "        #  print(\"desvio\")\n",
        "        #  print(desvio.data)\n",
        "        #  p=0\n",
        "\n",
        "  soma_parametros = None\n",
        "  media = None\n",
        "  desvio_padrao = None\n",
        "  desvio_padrao_aux = None\n",
        "\n",
        "  return 0\n"
      ],
      "metadata": {
        "id": "xx1W3JDcNZja"
      },
      "execution_count": 373,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# main\n",
        "faz o gerenciamento do treino, ataque e teste."
      ],
      "metadata": {
        "id": "MHjFAMr069h-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(wm):                                                                       # recebe a quantidade de workes maliciosos\n",
        "  models = [MLP().to(device) for _ in range(args.n_workers)]                      # cria uma lista de workers\n",
        "  optimizers = [optim.SGD(model.parameters(), lr= args.lr, momentum=args.momentum, weight_decay= args.l2) for model in models]  # SGD com momentum e L2 regularização (weight_decay)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  workers_maliciosos = []           # cria lista para armazenar os workes maliciosos\n",
        "  #workers_maliciosos = random.sample(range(args.n_workers), args.n_corrupted_workers)\n",
        "  for i in range(wm):               # marca os numeros dos workers maliciosos\n",
        "    workers_maliciosos.append(i)\n",
        "\n",
        "  # Criando os loaders de dados para cada trabalhador e o loader de teste global\n",
        "  trainloaders, testloader = prepare_mnist_dataset()\n",
        "  global_model = MLP().to(device)\n",
        "\n",
        "  # Loop de treinamento federado\n",
        "  for epoch in range(1, args.epochs + 1):\n",
        "    train(args, models, device, trainloaders, optimizers, criterion, epoch)\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "      if wm>1:\n",
        "        ataque(args, models, workers_maliciosos)\n",
        "      fedavg_aggregation(models, global_model)\n",
        "      test(global_model, device, testloader, epoch)"
      ],
      "metadata": {
        "id": "Zr1qRcvVNdWf"
      },
      "execution_count": 374,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  for wm in [args.n_corrupted_workers]:                  # passo com as quantidades de workers maliciosos em cada simulação\n",
        "    print(f\"Quantidade de workers maliciosos: {wm}\")\n",
        "    with open(f\"teste{wm}.txt\", 'w') as file:\n",
        "      file.write(f\"Quantidade de workers maliciosos: {wm}\\n\")\n",
        "    main(wm)\n",
        "    print(f\"Maior acurácia: {maior}\")\n",
        "    with open(f\"teste51.txt\", 'a') as file:\n",
        "      file.write(f\"Maior acurácia: {maior}\\n\")"
      ],
      "metadata": {
        "id": "UA6b67cJNgcL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRe3lng2C1jIbocOKwJrIt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}